{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neural-networks.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMJBFJAI0/nulpVXuQFswcw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andreaaraldo/machine-learning-for-networks/blob/master/04.neural_networks/neural_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHY0Omw3e1eb",
        "colab_type": "code",
        "outputId": "47409891-77e9-4b5c-d09a-1b36d8e4079b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.utils import plot_model\n",
        "\n",
        "\n",
        "# The following library is to plot the loss during training\n",
        "# https://github.com/stared/livelossplot\n",
        "!pip install git+git://github.com/stared/livelossplot.git\n",
        "from livelossplot.keras import PlotLossesCallback\n",
        "\n",
        "\n",
        "# Import the visualization library I prepared for you\n",
        "! wget https://raw.githubusercontent.com/andreaaraldo/machine-learning-for-networks/master/course_library/visualization.py\n",
        "from visualization import plot_conf_mat\n",
        "\n",
        "\n",
        "# The following is to be able to mount Google Drive\n",
        "from google.colab import drive\n",
        "\n",
        "from os.path import isfile"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/stared/livelossplot.git\n",
            "  Cloning git://github.com/stared/livelossplot.git to /tmp/pip-req-build-rdznneve\n",
            "  Running command git clone -q git://github.com/stared/livelossplot.git /tmp/pip-req-build-rdznneve\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from livelossplot==0.4.2) (3.2.0)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from livelossplot==0.4.2) (5.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot==0.4.2) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot==0.4.2) (1.18.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot==0.4.2) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot==0.4.2) (2.4.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot==0.4.2) (0.10.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot==0.4.2) (0.2.0)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot==0.4.2) (0.8.3)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot==0.4.2) (5.6.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot==0.4.2) (5.3.4)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot==0.4.2) (5.0.4)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot==0.4.2) (4.6.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot==0.4.2) (2.11.1)\n",
            "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot==0.4.2) (4.3.3)\n",
            "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot==0.4.2) (4.5.3)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot==0.4.2) (4.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->livelossplot==0.4.2) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->livelossplot==0.4.2) (45.2.0)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.3.3; sys_platform != \"win32\"->notebook->livelossplot==0.4.2) (0.6.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot==0.4.2) (0.6.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot==0.4.2) (0.3)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot==0.4.2) (1.4.2)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot==0.4.2) (0.4.4)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot==0.4.2) (2.1.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot==0.4.2) (0.8.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot==0.4.2) (3.1.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->notebook->livelossplot==0.4.2) (17.0.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat->notebook->livelossplot==0.4.2) (2.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->notebook->livelossplot==0.4.2) (1.1.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2.1->notebook->livelossplot==0.4.2) (4.4.2)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->notebook->livelossplot==0.4.2) (5.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook->livelossplot==0.4.2) (0.5.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot==0.4.2) (1.0.18)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot==0.4.2) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot==0.4.2) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot==0.4.2) (0.7.5)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->notebook->livelossplot==0.4.2) (0.1.8)\n",
            "Building wheels for collected packages: livelossplot\n",
            "  Building wheel for livelossplot (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for livelossplot: filename=livelossplot-0.4.2-cp36-none-any.whl size=12661 sha256=ba28a179535a062fa882cf22490a4edb28a21e7ccf7f009ce62bebfe3622547e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-u8wkdpfc/wheels/77/01/ea/cef3581d9c77ece0fd685cc3eb1cd92dc68d8117b361ac65dc\n",
            "Successfully built livelossplot\n",
            "Installing collected packages: livelossplot\n",
            "Successfully installed livelossplot-0.4.2\n",
            "--2020-03-17 14:13:56--  https://raw.githubusercontent.com/andreaaraldo/machine-learning-for-networks/master/course_library/visualization.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4406 (4.3K) [text/plain]\n",
            "Saving to: ‘visualization.py’\n",
            "\n",
            "visualization.py    100%[===================>]   4.30K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-03-17 14:13:56 (118 MB/s) - ‘visualization.py’ saved [4406/4406]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAyrD98bGJDl",
        "colab_type": "text"
      },
      "source": [
        "# Use case description\n",
        "\n",
        "The use case is from [KhConf19].\n",
        "\n",
        "\n",
        "**Goal** Estimate available bandwidth in a network via **passive measures**.\n",
        "\n",
        "More precisely:\n",
        "_Estimate the capacity available to a TCP flow_ (sharing links with other flows) observing\n",
        "* The time gaps between segments sent $g_{\\text{in}}$\n",
        "* The gaps between acks $g_\\text{ack}$\n",
        "\n",
        "\n",
        "\n",
        "![alt text](https://raw.githubusercontent.com/andreaaraldo/machine-learning-for-networks/master/04.neural_networks/img/ack.png)\n",
        "\\[Figure from [KhThesis19] \\]\n",
        "\n",
        "\n",
        "The auhtors set up the following testbed:\n",
        "\n",
        "\n",
        "![alt text](https://raw.githubusercontent.com/andreaaraldo/machine-learning-for-networks/master/04.neural_networks/img/testbed.png)\n",
        "\n",
        "\n",
        "Measures are collected in the **Video Receiver**. All the other machines just produce cross-traffic.\n",
        "\n",
        "Measures are recorded via an Endace Data Acquisition and Generation (DAG) card, which timestamp all packets in an extremely precise way.\n",
        "\n",
        "![alt text](https://www.endace.com/assets/images/products/DAG%209.5G4F_angled_small.png)\n",
        "\n",
        "([Producer website](https://www.endace.com/endace-high-speed-packet-capture-solutions/oem/dag/))\n",
        "\n",
        "**Why**: Knowing the available bandwidth, video streaming clients can properly choose the quality level to request."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXQAcMSZW4n_",
        "colab_type": "text"
      },
      "source": [
        "# Traces\n",
        "\n",
        "The description of the dataset can be found in the Appendix of Khangura's [PhD thesis](https://www.repo.uni-hannover.de/bitstream/handle/123456789/9219/Khangura_Sukhpreet_PhD_Thesis.pdf?sequence=3&isAllowed=y)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2u-6liSdGH62",
        "colab_type": "code",
        "outputId": "35d5a0b8-7a48-4a56-b95e-5c338a7d347a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "!wget https://www.ikt.uni-hannover.de/fileadmin/institut/Forschung/BandwidthEstimationTraces/BandwidthEstimationTraces.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-17 14:13:59--  https://www.ikt.uni-hannover.de/fileadmin/institut/Forschung/BandwidthEstimationTraces/BandwidthEstimationTraces.zip\n",
            "Resolving www.ikt.uni-hannover.de (www.ikt.uni-hannover.de)... 130.75.2.72\n",
            "Connecting to www.ikt.uni-hannover.de (www.ikt.uni-hannover.de)|130.75.2.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 941822 (920K) [application/zip]\n",
            "Saving to: ‘BandwidthEstimationTraces.zip’\n",
            "\n",
            "\r          Bandwidth   0%[                    ]       0  --.-KB/s               \rBandwidthEstimation 100%[===================>] 919.75K  5.64MB/s    in 0.2s    \n",
            "\n",
            "2020-03-17 14:13:59 (5.64 MB/s) - ‘BandwidthEstimationTraces.zip’ saved [941822/941822]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blbuQi5dWFRl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! unzip -o -q BandwidthEstimationTraces.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFiAO1GMWmR8",
        "colab_type": "code",
        "outputId": "2dd644ff-998b-42ab-c5fc-0b122f180818",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls BandwidthEstimationTraces"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "testing  training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRvAQC70cisA",
        "colab_type": "text"
      },
      "source": [
        "Training and test datasets are separated"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvKB2SxTWoYI",
        "colab_type": "code",
        "outputId": "66b22d84-1bdb-4f48-bd57-16c9bcf508ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "! ls BandwidthEstimationTraces/training"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MultiLinkCapacity100   TightLinkafterBottleneckLink\n",
            "SingleLinkCapacity100  TightLinkbeforeBottleneckLink\n",
            "SingleLinkCapacity50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FOIPBZocvZo",
        "colab_type": "text"
      },
      "source": [
        "For simplicity, we will just consider the case with a single link between client and server."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W306F9Azc826",
        "colab_type": "code",
        "outputId": "db9ede46-5104-4c45-9976-7abe9eec90c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "! ls BandwidthEstimationTraces/training/SingleLinkCapacity100"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25_et_100_C_5_delta  50_et_100_C_5_delta  75_et_100_C_5_delta\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPBsb5Axdd2z",
        "colab_type": "text"
      },
      "source": [
        "There are three sets of traces:\n",
        "* With cross traffic rate $\\lambda$=25 Mbps\n",
        "* With cross traffic rate $\\lambda$=50 Mbps\n",
        "* With cross traffic rate $\\lambda$=75 Mbps\n",
        "\n",
        "All rates are intended at the Ethernet level"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P210sSI9dDJv",
        "colab_type": "code",
        "outputId": "437f1a0d-a05f-41e4-d1b4-ba3fad39d0b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885
        }
      },
      "source": [
        "! ls BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "75_et_100_C_5_delta_100.csv  75_et_100_C_5_delta_55.csv\n",
            "75_et_100_C_5_delta_10.csv   75_et_100_C_5_delta_56.csv\n",
            "75_et_100_C_5_delta_11.csv   75_et_100_C_5_delta_57.csv\n",
            "75_et_100_C_5_delta_12.csv   75_et_100_C_5_delta_58.csv\n",
            "75_et_100_C_5_delta_13.csv   75_et_100_C_5_delta_59.csv\n",
            "75_et_100_C_5_delta_14.csv   75_et_100_C_5_delta_5.csv\n",
            "75_et_100_C_5_delta_15.csv   75_et_100_C_5_delta_60.csv\n",
            "75_et_100_C_5_delta_16.csv   75_et_100_C_5_delta_61.csv\n",
            "75_et_100_C_5_delta_17.csv   75_et_100_C_5_delta_62.csv\n",
            "75_et_100_C_5_delta_18.csv   75_et_100_C_5_delta_63.csv\n",
            "75_et_100_C_5_delta_19.csv   75_et_100_C_5_delta_64.csv\n",
            "75_et_100_C_5_delta_1.csv    75_et_100_C_5_delta_65.csv\n",
            "75_et_100_C_5_delta_20.csv   75_et_100_C_5_delta_66.csv\n",
            "75_et_100_C_5_delta_21.csv   75_et_100_C_5_delta_67.csv\n",
            "75_et_100_C_5_delta_22.csv   75_et_100_C_5_delta_68.csv\n",
            "75_et_100_C_5_delta_23.csv   75_et_100_C_5_delta_69.csv\n",
            "75_et_100_C_5_delta_24.csv   75_et_100_C_5_delta_6.csv\n",
            "75_et_100_C_5_delta_25.csv   75_et_100_C_5_delta_70.csv\n",
            "75_et_100_C_5_delta_26.csv   75_et_100_C_5_delta_71.csv\n",
            "75_et_100_C_5_delta_27.csv   75_et_100_C_5_delta_72.csv\n",
            "75_et_100_C_5_delta_28.csv   75_et_100_C_5_delta_73.csv\n",
            "75_et_100_C_5_delta_29.csv   75_et_100_C_5_delta_74.csv\n",
            "75_et_100_C_5_delta_2.csv    75_et_100_C_5_delta_75.csv\n",
            "75_et_100_C_5_delta_30.csv   75_et_100_C_5_delta_76.csv\n",
            "75_et_100_C_5_delta_31.csv   75_et_100_C_5_delta_77.csv\n",
            "75_et_100_C_5_delta_32.csv   75_et_100_C_5_delta_78.csv\n",
            "75_et_100_C_5_delta_33.csv   75_et_100_C_5_delta_79.csv\n",
            "75_et_100_C_5_delta_34.csv   75_et_100_C_5_delta_7.csv\n",
            "75_et_100_C_5_delta_35.csv   75_et_100_C_5_delta_80.csv\n",
            "75_et_100_C_5_delta_36.csv   75_et_100_C_5_delta_81.csv\n",
            "75_et_100_C_5_delta_37.csv   75_et_100_C_5_delta_82.csv\n",
            "75_et_100_C_5_delta_38.csv   75_et_100_C_5_delta_83.csv\n",
            "75_et_100_C_5_delta_39.csv   75_et_100_C_5_delta_84.csv\n",
            "75_et_100_C_5_delta_3.csv    75_et_100_C_5_delta_85.csv\n",
            "75_et_100_C_5_delta_40.csv   75_et_100_C_5_delta_86.csv\n",
            "75_et_100_C_5_delta_41.csv   75_et_100_C_5_delta_87.csv\n",
            "75_et_100_C_5_delta_42.csv   75_et_100_C_5_delta_88.csv\n",
            "75_et_100_C_5_delta_43.csv   75_et_100_C_5_delta_89.csv\n",
            "75_et_100_C_5_delta_44.csv   75_et_100_C_5_delta_8.csv\n",
            "75_et_100_C_5_delta_45.csv   75_et_100_C_5_delta_90.csv\n",
            "75_et_100_C_5_delta_46.csv   75_et_100_C_5_delta_91.csv\n",
            "75_et_100_C_5_delta_47.csv   75_et_100_C_5_delta_92.csv\n",
            "75_et_100_C_5_delta_48.csv   75_et_100_C_5_delta_93.csv\n",
            "75_et_100_C_5_delta_49.csv   75_et_100_C_5_delta_94.csv\n",
            "75_et_100_C_5_delta_4.csv    75_et_100_C_5_delta_95.csv\n",
            "75_et_100_C_5_delta_50.csv   75_et_100_C_5_delta_96.csv\n",
            "75_et_100_C_5_delta_51.csv   75_et_100_C_5_delta_97.csv\n",
            "75_et_100_C_5_delta_52.csv   75_et_100_C_5_delta_98.csv\n",
            "75_et_100_C_5_delta_53.csv   75_et_100_C_5_delta_99.csv\n",
            "75_et_100_C_5_delta_54.csv   75_et_100_C_5_delta_9.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTeZj2Z3eJwV",
        "colab_type": "text"
      },
      "source": [
        "Every experiment is repeated 100 times.\n",
        "\n",
        "Let's check the trace of one experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRwGpDEHeMkK",
        "colab_type": "code",
        "outputId": "5bce614e-2e70-4a58-e1c1-bd7d62e0fbc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        }
      },
      "source": [
        "filename = \"BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_33.csv\"\n",
        "df = pd.read_csv(filename)\n",
        "df"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>100</th>\n",
              "      <th>25</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.00060</td>\n",
              "      <td>4.9907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.99982</td>\n",
              "      <td>9.9443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.00340</td>\n",
              "      <td>14.9910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.01250</td>\n",
              "      <td>19.9870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.09670</td>\n",
              "      <td>25.0280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.10830</td>\n",
              "      <td>29.9820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.27700</td>\n",
              "      <td>35.3180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.27810</td>\n",
              "      <td>39.9750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1.24280</td>\n",
              "      <td>44.5390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1.42630</td>\n",
              "      <td>50.0520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1.44800</td>\n",
              "      <td>54.8200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1.33250</td>\n",
              "      <td>59.9640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1.39210</td>\n",
              "      <td>65.1400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1.57500</td>\n",
              "      <td>70.8650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1.50830</td>\n",
              "      <td>75.2580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1.49620</td>\n",
              "      <td>80.2280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1.68820</td>\n",
              "      <td>85.9380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1.81020</td>\n",
              "      <td>90.3930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1.76140</td>\n",
              "      <td>95.4080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1.73000</td>\n",
              "      <td>100.1100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        100        25\n",
              "0   1.00060    4.9907\n",
              "1   0.99982    9.9443\n",
              "2   1.00340   14.9910\n",
              "3   1.01250   19.9870\n",
              "4   1.09670   25.0280\n",
              "5   1.10830   29.9820\n",
              "6   1.27700   35.3180\n",
              "7   1.27810   39.9750\n",
              "8   1.24280   44.5390\n",
              "9   1.42630   50.0520\n",
              "10  1.44800   54.8200\n",
              "11  1.33250   59.9640\n",
              "12  1.39210   65.1400\n",
              "13  1.57500   70.8650\n",
              "14  1.50830   75.2580\n",
              "15  1.49620   80.2280\n",
              "16  1.68820   85.9380\n",
              "17  1.81020   90.3930\n",
              "18  1.76140   95.4080\n",
              "19  1.73000  100.1100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgpozAfk8YZv",
        "colab_type": "text"
      },
      "source": [
        "The header is not a sample. It just tells us the scenario, i.e. total channel capacity (Mbps) and available bandwith (Mbps).\n",
        "\n",
        "The columns are:\n",
        "* $g_\\text{in} / g_\\text{ack}$\n",
        "* Some sort of time stamp that we will ignore (not well described in the dataset)\n",
        "\n",
        "Let's rename the columns to avoid ambiguity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hj41JABXM355",
        "colab_type": "code",
        "outputId": "37bd6b24-7561-44b4-e6a6-9aa00131f21e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "df.columns=['gap_ratio', 'timestamp']\n",
        "df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gap_ratio</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.00060</td>\n",
              "      <td>4.9907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.99982</td>\n",
              "      <td>9.9443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.00340</td>\n",
              "      <td>14.9910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.01250</td>\n",
              "      <td>19.9870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.09670</td>\n",
              "      <td>25.0280</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   gap_ratio  timestamp\n",
              "0    1.00060     4.9907\n",
              "1    0.99982     9.9443\n",
              "2    1.00340    14.9910\n",
              "3    1.01250    19.9870\n",
              "4    1.09670    25.0280"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bv8RhycEQsDM",
        "colab_type": "text"
      },
      "source": [
        "# Feature engineering\n",
        "\n",
        "Each experiment will be a sample.\n",
        "\n",
        "The features of a sample are the elements of the histogram of the first column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFbGLRg6NfSM",
        "colab_type": "code",
        "outputId": "f6c71c47-9baf-4bd1-f756-97df65eeca6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        }
      },
      "source": [
        "plt.hist(df['gap_ratio'], density=True)\n",
        "\n",
        "# density:  True garantees that the area is 1 (such that hist approximates a \n",
        "#                 probability densitplt.hist(x)y function)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([2.46797799, 1.23398899, 0.6169945 , 1.23398899, 1.23398899,\n",
              "        1.23398899, 1.23398899, 0.6169945 , 0.6169945 , 1.85098349]),\n",
              " array([0.99982 , 1.080858, 1.161896, 1.242934, 1.323972, 1.40501 ,\n",
              "        1.486048, 1.567086, 1.648124, 1.729162, 1.8102  ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGmGhS1Ij/hfxNYmhR1D1zQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cncq7wY4PkDR",
        "colab_type": "text"
      },
      "source": [
        "However, the sequence of bins is chosen automatically by `matplotlib` and may change from an experiment to another.\n",
        "\n",
        "We need instead to describe all the experiments with a uniform set of features => The sequence of bins must be the same for all the experiments.\n",
        "\n",
        "To do so:\n",
        "* Open all files\n",
        "* Take the min and max gap from all the experiments\n",
        "* Divide the [min,max] interval uniformly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcGA9B5LQaSE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_filename(training_or_testing, capacity, cross_traff, other_number, \n",
        "                   experiment_id):  \n",
        "\n",
        "\n",
        "      filename = \"BandwidthEstimationTraces/\"+ \\\n",
        "                  training_or_testing + \"/SingleLinkCapacity\"+ capacity + \"/\" + \\\n",
        "                  cross_traff + \"_et_\"+capacity+\"_C_\"+ \\\n",
        "                  other_number + \"_delta/\"+ \\\n",
        "                  cross_traff + \"_et_\"+capacity+\"_C_\"+ \\\n",
        "                  other_number + \"_delta_\"+ \\\n",
        "                  str(experiment_id)+\".csv\"\n",
        "\n",
        "      return filename"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laMuRhZqv6dR",
        "colab_type": "text"
      },
      "source": [
        "Find the min and max"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWFro1CZkRua",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b28e6a7c-d0c7-4b26-866b-308bcdc93d4e"
      },
      "source": [
        "min_gap = float('inf')\n",
        "max_gap = 0\n",
        "\n",
        "capacity = '100'\n",
        "other_number = '5' # I don't know the meaning of this\n",
        "for cross_traff in ['25', '50', '75']:\n",
        "    for experiment_id in range(1,101):\n",
        "      print('Building capacity:', capacity, ', cross_traf:', cross_traff,\n",
        "            ', other_number:', other_number, ', experiment_id:', experiment_id)\n",
        "      filename = build_filename('training',capacity, cross_traff, other_number,\n",
        "                                experiment_id)\n",
        "      print('filename:', filename)\n",
        "\n",
        "      # print('Checking ',filename)\n",
        "      df = pd.read_csv(filename)\n",
        "      df.columns=['gap_ratio', 'timestamp']\n",
        "      trace_min = min( df['gap_ratio'] )\n",
        "      trace_max = max( df['gap_ratio'] )\n",
        "      min_gap = min ( [ min_gap, trace_min ] )\n",
        "      max_gap = max ( [ max_gap, trace_max ] )\n",
        "\n",
        "\n",
        "capacity = '50'\n",
        "other_number = '3'\n",
        "for cross_traff in ['12', '25', '37']:\n",
        "    for experiment_id in range(1,101):\n",
        "      filename = build_filename('training',capacity, cross_traff, other_number,\n",
        "                                experiment_id)\n",
        "\n",
        "      # print('Checking ',filename)\n",
        "      df = pd.read_csv(filename)\n",
        "      df.columns=['gap_ratio', 'timestamp']\n",
        "      trace_min = min( df['gap_ratio'] )\n",
        "      trace_max = max( df['gap_ratio'] )\n",
        "      min_gap = min ( [ min_gap, trace_min ] )\n",
        "      max_gap = max ( [ max_gap, trace_max ] )\n",
        "\n",
        "print('min_gap:', min_gap, ' max_gap:',max_gap)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 1\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_1.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 2\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_2.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 3\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_3.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 4\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_4.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 5\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_5.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 6\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_6.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 7\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_7.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 8\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_8.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 9\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_9.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 10\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_10.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 11\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_11.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 12\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_12.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 13\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_13.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 14\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_14.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 15\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_15.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 16\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_16.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 17\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_17.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 18\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_18.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 19\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_19.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 20\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_20.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 21\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_21.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 22\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_22.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 23\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_23.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 24\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_24.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 25\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_25.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 26\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_26.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 27\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_27.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 28\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_28.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 29\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_29.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 30\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_30.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 31\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_31.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 32\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_32.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 33\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_33.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 34\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_34.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 35\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_35.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 36\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_36.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 37\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_37.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 38\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_38.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 39\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_39.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 40\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_40.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 41\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_41.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 42\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_42.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 43\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_43.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 44\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_44.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 45\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_45.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 46\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_46.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 47\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_47.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 48\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_48.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 49\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_49.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 50\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_50.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 51\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_51.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 52\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_52.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 53\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_53.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 54\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_54.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 55\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_55.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 56\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_56.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 57\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_57.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 58\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_58.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 59\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_59.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 60\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_60.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 61\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_61.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 62\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_62.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 63\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_63.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 64\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_64.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 65\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_65.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 66\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_66.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 67\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_67.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 68\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_68.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 69\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_69.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 70\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_70.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 71\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_71.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 72\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_72.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 73\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_73.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 74\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_74.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 75\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_75.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 76\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_76.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 77\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_77.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 78\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_78.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 79\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_79.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 80\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_80.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 81\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_81.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 82\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_82.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 83\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_83.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 84\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_84.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 85\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_85.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 86\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_86.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 87\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_87.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 88\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_88.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 89\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_89.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 90\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_90.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 91\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_91.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 92\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_92.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 93\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_93.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 94\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_94.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 95\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_95.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 96\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_96.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 97\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_97.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 98\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_98.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 99\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_99.csv\n",
            "Building capacity: 100 , cross_traf: 25 , other_number: 5 , experiment_id: 100\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/25_et_100_C_5_delta/25_et_100_C_5_delta_100.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 1\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_1.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 2\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_2.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 3\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_3.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 4\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_4.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 5\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_5.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 6\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_6.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 7\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_7.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 8\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_8.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 9\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_9.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 10\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_10.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 11\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_11.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 12\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_12.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 13\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_13.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 14\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_14.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 15\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_15.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 16\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_16.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 17\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_17.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 18\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_18.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 19\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_19.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 20\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_20.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 21\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_21.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 22\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_22.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 23\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_23.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 24\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_24.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 25\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_25.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 26\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_26.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 27\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_27.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 28\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_28.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 29\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_29.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 30\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_30.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 31\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_31.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 32\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_32.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 33\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_33.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 34\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_34.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 35\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_35.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 36\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_36.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 37\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_37.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 38\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_38.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 39\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_39.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 40\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_40.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 41\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_41.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 42\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_42.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 43\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_43.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 44\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_44.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 45\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_45.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 46\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_46.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 47\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_47.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 48\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_48.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 49\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_49.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 50\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_50.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 51\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_51.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 52\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_52.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 53\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_53.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 54\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_54.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 55\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_55.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 56\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_56.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 57\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_57.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 58\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_58.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 59\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_59.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 60\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_60.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 61\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_61.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 62\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_62.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 63\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_63.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 64\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_64.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 65\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_65.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 66\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_66.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 67\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_67.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 68\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_68.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 69\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_69.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 70\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_70.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 71\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_71.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 72\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_72.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 73\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_73.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 74\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_74.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 75\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_75.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 76\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_76.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 77\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_77.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 78\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_78.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 79\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_79.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 80\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_80.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 81\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_81.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 82\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_82.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 83\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_83.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 84\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_84.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 85\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_85.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 86\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_86.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 87\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_87.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 88\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_88.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 89\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_89.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 90\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_90.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 91\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_91.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 92\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_92.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 93\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_93.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 94\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_94.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 95\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_95.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 96\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_96.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 97\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_97.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 98\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_98.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 99\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_99.csv\n",
            "Building capacity: 100 , cross_traf: 50 , other_number: 5 , experiment_id: 100\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/50_et_100_C_5_delta/50_et_100_C_5_delta_100.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 1\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_1.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 2\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_2.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 3\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_3.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 4\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_4.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 5\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_5.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 6\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_6.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 7\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_7.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 8\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_8.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 9\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_9.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 10\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_10.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 11\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_11.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 12\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_12.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 13\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_13.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 14\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_14.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 15\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_15.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 16\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_16.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 17\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_17.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 18\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_18.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 19\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_19.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 20\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_20.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 21\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_21.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 22\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_22.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 23\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_23.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 24\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_24.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 25\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_25.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 26\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_26.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 27\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_27.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 28\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_28.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 29\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_29.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 30\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_30.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 31\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_31.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 32\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_32.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 33\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_33.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 34\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_34.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 35\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_35.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 36\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_36.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 37\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_37.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 38\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_38.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 39\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_39.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 40\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_40.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 41\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_41.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 42\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_42.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 43\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_43.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 44\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_44.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 45\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_45.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 46\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_46.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 47\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_47.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 48\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_48.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 49\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_49.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 50\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_50.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 51\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_51.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 52\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_52.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 53\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_53.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 54\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_54.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 55\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_55.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 56\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_56.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 57\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_57.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 58\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_58.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 59\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_59.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 60\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_60.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 61\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_61.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 62\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_62.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 63\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_63.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 64\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_64.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 65\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_65.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 66\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_66.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 67\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_67.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 68\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_68.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 69\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_69.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 70\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_70.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 71\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_71.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 72\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_72.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 73\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_73.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 74\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_74.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 75\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_75.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 76\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_76.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 77\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_77.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 78\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_78.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 79\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_79.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 80\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_80.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 81\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_81.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 82\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_82.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 83\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_83.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 84\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_84.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 85\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_85.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 86\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_86.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 87\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_87.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 88\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_88.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 89\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_89.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 90\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_90.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 91\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_91.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 92\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_92.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 93\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_93.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 94\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_94.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 95\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_95.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 96\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_96.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 97\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_97.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 98\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_98.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 99\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_99.csv\n",
            "Building capacity: 100 , cross_traf: 75 , other_number: 5 , experiment_id: 100\n",
            "filename: BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_100.csv\n",
            "min_gap: 0.95975  max_gap: 2.318\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cS7y7cT-XmpQ",
        "colab_type": "text"
      },
      "source": [
        "Let's create the bins that we will use for all experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPnUK2tiXuEB",
        "colab_type": "code",
        "outputId": "6695670f-35b9-4dbd-8bca-b9773b57d996",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "N = 8 # num of bins\n",
        "\n",
        "bin_size = (max_gap-min_gap)/N \n",
        "bins = [min_gap + i * bin_size for i in range(0, N+1)]\n",
        "bins"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.95975,\n",
              " 1.1295312499999999,\n",
              " 1.2993125,\n",
              " 1.4690937499999999,\n",
              " 1.638875,\n",
              " 1.8086562499999999,\n",
              " 1.9784375,\n",
              " 2.14821875,\n",
              " 2.318]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atGuyYNKYR-1",
        "colab_type": "text"
      },
      "source": [
        "Just as a visual check, let's plot again the previous histogram with these new bins"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWkFTXN0YWH2",
        "colab_type": "code",
        "outputId": "0766b3f7-3277-43c6-b5be-9e54ae15d66b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "filename = \"BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_33.csv\"\n",
        "df = pd.read_csv(filename)\n",
        "df.columns=['gap_ratio', 'timestamp']\n",
        "hist_values, bins, bars = plt.hist( df['gap_ratio'], density=True, bins=bins)\n",
        "print(hist_values )"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.76697957 0.88348978 1.17798638 0.88348978 0.88348978 0.29449659\n",
            " 0.         0.        ]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyjd51oBcD8n",
        "colab_type": "text"
      },
      "source": [
        "Let's obtain the histogram for all the experiments. For each experiment, we construct a feature vector:\n",
        "\n",
        "  `[bin1_freq, bin2_freq, ...., binN_freq]`\n",
        "\n",
        "and a label `avail_bandwidth`.\n",
        "\n",
        "We write these operations in a function `construct_dataset` that we will then use for the training and the test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCEHvKgTaGjN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_file(filename, bins):\n",
        "      df = pd.read_csv(filename)\n",
        "\n",
        "      # Observe that for each experiment, the available bandwidth corresponds \n",
        "      # to the name of the second column\n",
        "      avail_band = df.columns[1]\n",
        "\n",
        "\n",
        "      df.columns=['gap_ratio', 'timestamp']\n",
        "\n",
        "      histogram_values, bins, bars = plt.hist( df['gap_ratio'], density=True, \n",
        "                                              bins=bins)\n",
        "\n",
        "      return histogram_values, avail_band\n",
        "\n",
        "\n",
        "\n",
        "def construct_dataset(training_or_testing, bins):\n",
        "\n",
        "  X = np.empty((0,N), int)\n",
        "  y = []\n",
        "\n",
        "  capacity = '100'\n",
        "  print('Starting with capacity ', capacity)\n",
        "  other_number = '5'\n",
        "  for cross_traff in ['25', '50', '75']:\n",
        "    for experiment_id in range(1,101):\n",
        "      filename = build_filename(training_or_testing, capacity, cross_traff, \n",
        "                                other_number, experiment_id)\n",
        "\n",
        "      histogram_values, avail_band = process_file(filename, bins)\n",
        "\n",
        "      X = np.vstack(( X, histogram_values) )\n",
        "      y.append(avail_band)\n",
        "\n",
        "  capacity = '50'\n",
        "  print('Starting with capacity ', capacity)\n",
        "  other_number = '3'\n",
        "  for cross_traff in ['12', '25', '37']:\n",
        "    for experiment_id in range(1,101):\n",
        "      filename = build_filename(training_or_testing, capacity, cross_traff, \n",
        "                                other_number, experiment_id)\n",
        "\n",
        "      histogram_values, avail_band = process_file(filename, bins)\n",
        "\n",
        "      X = np.vstack(( X, histogram_values) )\n",
        "      y.append(avail_band)\n",
        "\n",
        "\n",
        "\n",
        "  return X,y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6Ekap9q-_ia",
        "colab_type": "code",
        "outputId": "411b87b9-8547-4ab7-9244-3813582a3b70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 719
        }
      },
      "source": [
        "X_train, y_train = construct_dataset(\"training\", bins)\n",
        "X_test, y_test = construct_dataset(\"testing\", bins)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting with capacity  100\n",
            "Starting with capacity  50\n",
            "Starting with capacity  100\n",
            "Starting with capacity  50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-78a80b5ecaf7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruct_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruct_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"testing\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-25-46086ab2ece7>\u001b[0m in \u001b[0;36mconstruct_dataset\u001b[0;34m(training_or_testing, bins)\u001b[0m\n\u001b[1;32m     42\u001b[0m                                 other_number, experiment_id)\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m       \u001b[0mhistogram_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavail_band\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m       \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistogram_values\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-46086ab2ece7>\u001b[0m in \u001b[0;36mprocess_file\u001b[0;34m(filename, bins)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprocess_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m       \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0;31m# Observe that for each experiment, the available bandwidth corresponds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0;31m# to the name of the second column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'BandwidthEstimationTraces/testing/SingleLinkCapacity50/12_et_50_C_3_delta/12_et_50_C_3_delta_1.csv' does not exist: b'BandwidthEstimationTraces/testing/SingleLinkCapacity50/12_et_50_C_3_delta/12_et_50_C_3_delta_1.csv'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlzCxsjZDnc0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STsxNvnVB-ZN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('X_train\\n', X_train[0:6, :] )\n",
        "print('\\n\\ny_train\\n',y_train.transpose() )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K03VxUJ1idJp",
        "colab_type": "text"
      },
      "source": [
        "With NN is important to **scale** the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CpWt6qKivif",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print('X_train_scaled', X_train_scaled[0:6, :] )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_iC8vrtk3uE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsDxd9KuCnzg",
        "colab_type": "text"
      },
      "source": [
        "# Build a NN model\n",
        "\n",
        "To train faster, change the runtime to GPU.\n",
        "\n",
        "Now, let's build a NN architecture. The size of each sample is:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLRGAHB2oPJJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_size = X_train_scaled.shape[1]\n",
        "print('The sample size is ', sample_size, \n",
        "      ', which should correspond to the number of bins ', N)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0zcfeTEC0KF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_of_classes = 3\n",
        "\n",
        "model = Sequential([\n",
        "  Dense(4, input_dim=sample_size, activation='relu' ),\n",
        "  Dense(num_of_classes, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# The first layer has 4 neurons and take 8 input values.\n",
        "# In the first layer, you always need to specify the input_dim\n",
        "#\n",
        "# Note that each layer adds implicitly a bias term (we do not need to care about \n",
        "# it)\n",
        "#\n",
        "# The last layer is a softmax, since we are doing classification\n",
        "\n",
        "\n",
        "model.summary()\n",
        "plot_model(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2WOD4aNt3HA",
        "colab_type": "text"
      },
      "source": [
        "`None` means that the batch size can be any value.\n",
        "\n",
        "Compile the model, i.e., decide the loss function to minimize, the optimization function and the metrics to show"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0eA8qTowf16",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\", \n",
        "              optimizer=keras.optimizers.SGD(lr=0.01) ,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0SfFwbExxs9",
        "colab_type": "text"
      },
      "source": [
        "From Ch.10 of [Ge19]:\n",
        "\n",
        "Loss function:\n",
        "* Use `sparse_categorical_cross entropy` when there is just one target value (as in our case). \n",
        "* If target were one-hot encoded, e.g. [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], then use `categorical_crossentropy` instead. \n",
        "* In binary classification then use `sigmoid` activation function in the output layer instead of the `softmax` and `binary_crossentropy` loss.\n",
        "\n",
        "Optimizer:\n",
        "* We are using Stochastic Gradient Descent with learning rate $\\eta=0.01$\n",
        "\n",
        "Metrics:\n",
        "* We are asking Keras to show at each epoch the accuracy. Note that the accuracy value is ignored during training. This metric is just visualized"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AZY1xtwl0jq",
        "colab_type": "text"
      },
      "source": [
        "# Training\n",
        "\n",
        "To train faster, change the runtime to GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xebwBVml9sSw",
        "colab_type": "text"
      },
      "source": [
        "### Simple training and testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_Y4xLk75lH_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 500\n",
        "\n",
        "\n",
        "plot_losses = PlotLossesCallback()  # Just to plot the evolution of \n",
        "                                    # loss during training\n",
        "\n",
        "model.fit(X_train_scaled, y_train, epochs=epochs, \n",
        "                    callbacks = [plot_losses] )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IADgsSbyEcUh",
        "colab_type": "text"
      },
      "source": [
        "Let's check the performance on the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6u27rGU0EqJi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(X_test_scaled)\n",
        "y_pred[0:5,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvWVnm5pG505",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_proba = model.predict(X_test_scaled)\n",
        "print( 'y_proba\\n', y_proba[0:5] )\n",
        "\n",
        "y_pred = model.predict_classes(X_test_scaled)\n",
        "print( 'y_pred\\n', y_pred[0:5] )\n",
        "\n",
        "class_names = np.array( ['low', 'mid', 'hig'] )\n",
        "plot_conf_mat(y_test, y_pred, class_names)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUTc4Xrx9x11",
        "colab_type": "text"
      },
      "source": [
        "### Automate build"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPEVn53q9J5y",
        "colab_type": "text"
      },
      "source": [
        "If you run `model.fit` again, you will not start from scratch, but you will start from current weights.\n",
        "\n",
        "Since we want to compare different training strategies, we will build a model from scratch every time.\n",
        "\n",
        "We write a function to automate the building process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LR0eiQu391YP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "  # Reproducibility: to ensure every time we generate a model, its weights are \n",
        "  #     always initialized in the same way\n",
        "  # To know more: \n",
        "  #       https://machinelearningmastery.com/reproducible-results-neural-networks-keras/\n",
        "  np.random.seed(6)\n",
        "  tf.set_random_seed(4)\n",
        "\n",
        "\n",
        "  model = Sequential([\n",
        "   Dense(4, input_dim=sample_size, activation='relu'),\n",
        "   Dense(num_of_classes, activation='softmax')\n",
        "  ])\n",
        "\n",
        "  model.compile(loss='sparse_categorical_crossentropy',\n",
        "                optimizer=keras.optimizers.SGD(lr=0.01),\n",
        "                metrics=['accuracy']\n",
        "                )\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6IQYJ3N_KSM",
        "colab_type": "text"
      },
      "source": [
        "### Save and load models\n",
        "\n",
        "Training a neural network may take long time and you don't want to do it every time. Once you've trained a model, it is better to save it, so that you can use it immediately for prediction next times.\n",
        "\n",
        "Unfortunately, the storage on Google is reset every time. You need to store all persistent data in you Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blP3nm_stBVH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mount_point = '/content/gdrive' # Always the same, don't change it\n",
        "drive.mount(mount_point, force_remount=True)\n",
        "drive_path = mount_point + '/My Drive/' # Always the same, don't change it\n",
        "my_path = drive_path + \\\n",
        "  'tsp/teaching/data-science-for-networks/img-from-code/04.neural-networks/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPT7aAEQ0d_q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_losses = PlotLossesCallback()  # Just to plot the evolution of \n",
        "                                    # loss during training\n",
        "\n",
        "nn_file = my_path + 'nn1.h5'\n",
        "\n",
        "\n",
        "if not isfile(nn_file):\n",
        "  ###### Build and train the model\n",
        "\n",
        "  model = build_model()\n",
        "  history = model.fit(X_train_scaled, y_train, epochs=epochs, \n",
        "                    callbacks = [plot_losses] )\n",
        "  \n",
        "  # Save the trained model\n",
        "  model.save( nn_file )\n",
        "\n",
        "  # Save the history as well\n",
        "  pd.DataFrame.from_dict(history.history).to_csv(nn_file+'.hist.csv', \n",
        "                                                 index=False)\n",
        "\n",
        "else:\n",
        "  ##### Load the model already trained\n",
        "  model = load_model( nn_file )\n",
        "\n",
        "  # Load the history as well\n",
        "  hist_df = pd.read_csv(nn_file+'.hist.csv')\n",
        "\n",
        "  # Plot the history\n",
        "  hist_df.plot()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Po0F-f7_8a3",
        "colab_type": "text"
      },
      "source": [
        "We can automate this code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPQV5g4xvssJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_or_load_model(nn_file, X_tr, y_tr):\n",
        "  plot_losses = PlotLossesCallback()  # Just to plot the evolution of \n",
        "                                    # loss during training\n",
        "\n",
        "  if not isfile(nn_file):\n",
        "    model = build_model()\n",
        "    history = model.fit(X_tr, y_tr, epochs=epochs, \n",
        "                      callbacks = [plot_losses] )\n",
        "    model.save( nn_file )\n",
        "\n",
        "    # From https://stackoverflow.com/a/59854096/2110769\n",
        "    pd.DataFrame.from_dict(history.history).to_csv(nn_file+'.hist.csv',\n",
        "                                                   index=False)\n",
        "    return model\n",
        "    \n",
        "  else:\n",
        "    model = load_model( nn_file )\n",
        "    hist_df = pd.read_csv(nn_file+'.hist.csv')\n",
        "    hist_df.plot()\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxO4wqr5FMQO",
        "colab_type": "text"
      },
      "source": [
        "Let's run this function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxP6x7ZXFzd5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn_file = my_path + 'nn1.h5'\n",
        "\n",
        "model = train_or_load_model(nn_file, X_train_scaled, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPfE63cIGSt5",
        "colab_type": "text"
      },
      "source": [
        "# Importance of randomness"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpzBqAbDrrOj",
        "colab_type": "text"
      },
      "source": [
        "We can still improve\n",
        "\n",
        "Hypothesis on a possible problem:\n",
        "* Stochastic gradient descent works well when the gradient of the loss function in each sample \n",
        "$$\n",
        "  \\nabla J (\\boldsymbol{\\theta},x^{(i)}, y^{(i)})\n",
        "$$\n",
        "is an unbiased estimate of the true loss function\n",
        "$$\n",
        "  \\nabla J (\\boldsymbol{\\theta},\\mathbf{X}, \\mathbf{y}) =\n",
        "  \\frac{1}{m} \\sum_{i=1}^m \\nabla J (\\boldsymbol{\\theta},x^{(i)}, y^{(i)})\n",
        "$$\n",
        "Therefore, the sequence of $x^{(i)},y^{(i)}$ should \"look\" randomly chosen. In our case, instead, our training samples have a specific order."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdMFMdZPWw_6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train.transpose()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EI6PZrAiYaty",
        "colab_type": "text"
      },
      "source": [
        "How can we solve this?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ve6sRdoKYcis",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_scaled_sh, y_train_sh = shuffle(X_train_scaled, y_train, random_state=3)\n",
        "\n",
        "nn_file = my_path + 'nn2.h5'\n",
        "\n",
        "model = train_or_load_model(nn_file, X_train_scaled_sh, y_train_sh)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYEpkBPclnch",
        "colab_type": "text"
      },
      "source": [
        "Way better now!\n",
        "\n",
        "Let's test the performance on the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kUbnfPglvWO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict_classes(X_test_scaled)\n",
        "\n",
        "plot_conf_mat(y_test,y_pred, class_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fPMkJSexgSY",
        "colab_type": "text"
      },
      "source": [
        "# Evaluate overfitting\n",
        "\n",
        "We can still improve\n",
        "\n",
        "Hypothesis:\n",
        "* The NN may be overfitting\n",
        "\n",
        "How do we verify this?\n",
        "\n",
        "**Always** better to divide the training set in training and validation:\n",
        "* Loss minimization is performed only on the training set\n",
        "* we also plot the evolution of the loss and the accuracy on the validation\n",
        "    * It does not impact the training\n",
        "    * It just allows us to check:\n",
        "        * If training error decreases but validation error increases => OVERFITTING\n",
        "\n",
        "\n",
        "Let's modify our `train_or_load_model` function accordingly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqhOSFwCJwMP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "help(train_test_split)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToyJ5gpvIM3Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_or_load_model(nn_file, X_tr, y_tr):\n",
        "  plot_losses = PlotLossesCallback()  # Just to plot the evolution of \n",
        "                                    # loss during training\n",
        "\n",
        "  if not isfile(nn_file):\n",
        "    model = build_model()\n",
        "\n",
        "    ##### MODIFIED PART{\n",
        "    X_train_part, y_train_part, X_valid_part, y_valid_part = \\\n",
        "      train_test_split(X_tr, y_tr, test_size=0.2, random_state=3)\n",
        "\n",
        "    history = model.fit(X_tr, y_tr, epochs=epochs, \n",
        "                        callbacks = [plot_losses],\n",
        "                        validation_data = (X_valid_part, y_valid_part)\n",
        "                        )\n",
        "    ##### MODIFIED PART}\n",
        "    \n",
        "    model.save( nn_file )\n",
        "\n",
        "    # From https://stackoverflow.com/a/59854096/2110769\n",
        "    pd.DataFrame.from_dict(history.history).to_csv(nn_file+'.hist.csv',\n",
        "                                                   index=False)\n",
        "    return model\n",
        "    \n",
        "  else:\n",
        "    model = load_model( nn_file )\n",
        "    hist_df = pd.read_csv(nn_file+'.hist.csv')\n",
        "    hist_df.plot()\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hlfm6hS1yiC_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn_file = my_path + 'nn3.h5'\n",
        "model = train_or_load_model(nn_file, X_train_scaled_sh, y_train_sh)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6u0cMK1JDKLH",
        "colab_type": "text"
      },
      "source": [
        "# Limitation of the work\n",
        "\n",
        "* Only a finite set of available bandwidth values are used (25, 50, 75 Mbps). In reality, any value can occur => Need to extend the test and validation test with random bandwidth values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VYbiDvHxLtU",
        "colab_type": "text"
      },
      "source": [
        "# References\n",
        "\n",
        "* [Ge19] Geron, Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2019, O'Reilly\n",
        "* [KhConf19] Khangura, S. K. (2019). Neural Network-based Available Bandwidth Estimation from TCP Sender-side Measurements. In IEEE/IFIP PEMWN.\n",
        "* [KhThesis19] Khangura, S. K. (2019). Machine Learning-based Available Bandwidth Estimation. Leibniz University."
      ]
    }
  ]
}