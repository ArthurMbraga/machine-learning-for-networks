{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neural-networks.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOmib9wvwqWLypIZ0AJt14X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andreaaraldo/machine-learning-for-networks/blob/master/04.neural_networks/neural_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHY0Omw3e1eb",
        "colab_type": "code",
        "outputId": "25e3df8d-968d-46b9-c587-92be958f7e4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 808
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
        "\n",
        "\n",
        "\n",
        "!pip install category_encoders\n",
        "import category_encoders as ce\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# The following library is to plot the loss during training\n",
        "# https://github.com/stared/livelossplot\n",
        "! pip install livelossplot\n",
        "from livelossplot import PlotLossesKerasTF\n",
        "\n",
        "\n",
        "# Import the visualization library I prepared for you\n",
        "! wget https://raw.githubusercontent.com/andreaaraldo/machine-learning-for-networks/master/course_library/visualization.py\n",
        "from visualization import plot_conf_mat\n",
        "\n",
        "\n",
        "# The following is to be able to mount Google Drive\n",
        "from google.colab import drive\n",
        "\n",
        "import os\n",
        "from os.path import isfile"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: category_encoders in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "Requirement already satisfied: statsmodels>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.10.2)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.0.3)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.4.1)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.5.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.18.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2.8.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->category_encoders) (0.14.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.4.1->category_encoders) (1.12.0)\n",
            "Requirement already satisfied: livelossplot in /usr/local/lib/python3.6/dist-packages (0.5.0)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from livelossplot) (5.5.0)\n",
            "Requirement already satisfied: matplotlib; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from livelossplot) (3.2.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (46.1.3)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (1.0.18)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (0.8.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (4.3.3)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (2.1.3)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (4.8.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib; python_version >= \"3.6\"->livelossplot) (1.18.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib; python_version >= \"3.6\"->livelossplot) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib; python_version >= \"3.6\"->livelossplot) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib; python_version >= \"3.6\"->livelossplot) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib; python_version >= \"3.6\"->livelossplot) (2.4.6)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->livelossplot) (0.1.9)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->livelossplot) (1.12.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->livelossplot) (0.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->livelossplot) (0.6.0)\n",
            "--2020-04-06 17:18:56--  https://raw.githubusercontent.com/andreaaraldo/machine-learning-for-networks/master/course_library/visualization.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12412 (12K) [text/plain]\n",
            "Saving to: ‘visualization.py.1’\n",
            "\n",
            "visualization.py.1  100%[===================>]  12.12K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-04-06 17:18:56 (49.8 MB/s) - ‘visualization.py.1’ saved [12412/12412]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6IQYJ3N_KSM",
        "colab_type": "text"
      },
      "source": [
        "### Mount your Google Drive\n",
        "\n",
        "Training a neural network may take long time and you don't want to do it every time. Once you've trained a model, it is better to save it, so that you can use it immediately for prediction next times.\n",
        "\n",
        "Unfortunately, the storage on Google is reset every time. You need to store all persistent data in you Google Drive.\n",
        "\n",
        "You need therefore to mount your Google Drive, which you will use later in this notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blP3nm_stBVH",
        "colab_type": "code",
        "outputId": "263dbd9c-fa2d-4ec9-b22e-c2eef9158ca0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "mount_point = '/content/gdrive' # Always the same, don't change it\n",
        "drive.mount(mount_point, force_remount=True)\n",
        "drive_path = mount_point + '/My Drive/' # Always the same, don't change it\n",
        "my_path = drive_path + \\\n",
        "  'tsp/teaching/data-science-for-networks/img-from-code/04.neural-networks/'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAyrD98bGJDl",
        "colab_type": "text"
      },
      "source": [
        "# Use case description\n",
        "\n",
        "The use case is from [KhConf19].\n",
        "\n",
        "\n",
        "**Goal** Estimate available bandwidth in a network via **passive measures**.\n",
        "\n",
        "More precisely:\n",
        "_Estimate the capacity available to a TCP flow_ (sharing links with other flows) observing\n",
        "* The time gaps between segments sent $g_{\\text{in}}$\n",
        "* The gaps between acks $g_\\text{ack}$\n",
        "\n",
        "\n",
        "\n",
        "![alt text](https://raw.githubusercontent.com/andreaaraldo/machine-learning-for-networks/master/04.neural_networks/img/ack.png)\n",
        "\\[Figure from [KhThesis19] \\]\n",
        "\n",
        "\n",
        "The auhtors set up the following testbed:\n",
        "\n",
        "\n",
        "![alt text](https://raw.githubusercontent.com/andreaaraldo/machine-learning-for-networks/master/04.neural_networks/img/testbed.png)\n",
        "\n",
        "\n",
        "Measures are collected in the **Video Receiver**. All the other machines just produce cross-traffic.\n",
        "\n",
        "Measures are recorded via an Endace Data Acquisition and Generation (DAG) card, which timestamp all packets in an extremely precise way.\n",
        "\n",
        "![alt text](https://www.endace.com/assets/images/products/DAG%209.5G4F_angled_small.png)\n",
        "\n",
        "([Producer website](https://www.endace.com/endace-high-speed-packet-capture-solutions/oem/dag/))\n",
        "\n",
        "**Why**: Knowing the available bandwidth, video streaming clients can properly choose the quality level to request."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXQAcMSZW4n_",
        "colab_type": "text"
      },
      "source": [
        "# Traces\n",
        "\n",
        "The description of the dataset can be found in the Appendix of Khangura's [PhD thesis](https://www.repo.uni-hannover.de/bitstream/handle/123456789/9219/Khangura_Sukhpreet_PhD_Thesis.pdf?sequence=3&isAllowed=y)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2u-6liSdGH62",
        "colab_type": "code",
        "outputId": "7a602907-6fce-4cd0-d8b5-46a45ffa95d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        }
      },
      "source": [
        "!wget https://www.ikt.uni-hannover.de/fileadmin/institut/Forschung/BandwidthEstimationTraces/BandwidthEstimationTraces.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-06 17:17:05--  https://www.ikt.uni-hannover.de/fileadmin/institut/Forschung/BandwidthEstimationTraces/BandwidthEstimationTraces.zip\n",
            "Resolving www.ikt.uni-hannover.de (www.ikt.uni-hannover.de)... 130.75.2.72\n",
            "Connecting to www.ikt.uni-hannover.de (www.ikt.uni-hannover.de)|130.75.2.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 941822 (920K) [application/zip]\n",
            "Saving to: ‘BandwidthEstimationTraces.zip’\n",
            "\n",
            "BandwidthEstimation 100%[===================>] 919.75K   432KB/s    in 2.1s    \n",
            "\n",
            "2020-04-06 17:17:08 (432 KB/s) - ‘BandwidthEstimationTraces.zip’ saved [941822/941822]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blbuQi5dWFRl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! unzip -o -q BandwidthEstimationTraces.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFiAO1GMWmR8",
        "colab_type": "code",
        "outputId": "6af7393e-9010-4bcd-945c-ca52e35a2e40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls BandwidthEstimationTraces"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "testing  training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRvAQC70cisA",
        "colab_type": "text"
      },
      "source": [
        "Training and test datasets are separated"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvKB2SxTWoYI",
        "colab_type": "code",
        "outputId": "45e30ef9-c66f-43ad-a3fc-67766bff0595",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "! ls BandwidthEstimationTraces/training"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MultiLinkCapacity100   TightLinkafterBottleneckLink\n",
            "SingleLinkCapacity100  TightLinkbeforeBottleneckLink\n",
            "SingleLinkCapacity50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FOIPBZocvZo",
        "colab_type": "text"
      },
      "source": [
        "For simplicity, we will just consider the case with a single link between client and server."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W306F9Azc826",
        "colab_type": "code",
        "outputId": "ec550b98-2510-41b6-f65a-6ff20bde92ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "! ls BandwidthEstimationTraces/training/SingleLinkCapacity100"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25_et_100_C_5_delta  50_et_100_C_5_delta  75_et_100_C_5_delta\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPBsb5Axdd2z",
        "colab_type": "text"
      },
      "source": [
        "There are three sets of traces:\n",
        "* With cross traffic rate $\\lambda$=25 Mbps\n",
        "* With cross traffic rate $\\lambda$=50 Mbps\n",
        "* With cross traffic rate $\\lambda$=75 Mbps\n",
        "\n",
        "All rates are intended at the Ethernet level"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P210sSI9dDJv",
        "colab_type": "code",
        "outputId": "33e8a714-ae4f-401c-9688-56cd6e29c29e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        }
      },
      "source": [
        "! ls BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "75_et_100_C_5_delta_100.csv  75_et_100_C_5_delta_55.csv\n",
            "75_et_100_C_5_delta_10.csv   75_et_100_C_5_delta_56.csv\n",
            "75_et_100_C_5_delta_11.csv   75_et_100_C_5_delta_57.csv\n",
            "75_et_100_C_5_delta_12.csv   75_et_100_C_5_delta_58.csv\n",
            "75_et_100_C_5_delta_13.csv   75_et_100_C_5_delta_59.csv\n",
            "75_et_100_C_5_delta_14.csv   75_et_100_C_5_delta_5.csv\n",
            "75_et_100_C_5_delta_15.csv   75_et_100_C_5_delta_60.csv\n",
            "75_et_100_C_5_delta_16.csv   75_et_100_C_5_delta_61.csv\n",
            "75_et_100_C_5_delta_17.csv   75_et_100_C_5_delta_62.csv\n",
            "75_et_100_C_5_delta_18.csv   75_et_100_C_5_delta_63.csv\n",
            "75_et_100_C_5_delta_19.csv   75_et_100_C_5_delta_64.csv\n",
            "75_et_100_C_5_delta_1.csv    75_et_100_C_5_delta_65.csv\n",
            "75_et_100_C_5_delta_20.csv   75_et_100_C_5_delta_66.csv\n",
            "75_et_100_C_5_delta_21.csv   75_et_100_C_5_delta_67.csv\n",
            "75_et_100_C_5_delta_22.csv   75_et_100_C_5_delta_68.csv\n",
            "75_et_100_C_5_delta_23.csv   75_et_100_C_5_delta_69.csv\n",
            "75_et_100_C_5_delta_24.csv   75_et_100_C_5_delta_6.csv\n",
            "75_et_100_C_5_delta_25.csv   75_et_100_C_5_delta_70.csv\n",
            "75_et_100_C_5_delta_26.csv   75_et_100_C_5_delta_71.csv\n",
            "75_et_100_C_5_delta_27.csv   75_et_100_C_5_delta_72.csv\n",
            "75_et_100_C_5_delta_28.csv   75_et_100_C_5_delta_73.csv\n",
            "75_et_100_C_5_delta_29.csv   75_et_100_C_5_delta_74.csv\n",
            "75_et_100_C_5_delta_2.csv    75_et_100_C_5_delta_75.csv\n",
            "75_et_100_C_5_delta_30.csv   75_et_100_C_5_delta_76.csv\n",
            "75_et_100_C_5_delta_31.csv   75_et_100_C_5_delta_77.csv\n",
            "75_et_100_C_5_delta_32.csv   75_et_100_C_5_delta_78.csv\n",
            "75_et_100_C_5_delta_33.csv   75_et_100_C_5_delta_79.csv\n",
            "75_et_100_C_5_delta_34.csv   75_et_100_C_5_delta_7.csv\n",
            "75_et_100_C_5_delta_35.csv   75_et_100_C_5_delta_80.csv\n",
            "75_et_100_C_5_delta_36.csv   75_et_100_C_5_delta_81.csv\n",
            "75_et_100_C_5_delta_37.csv   75_et_100_C_5_delta_82.csv\n",
            "75_et_100_C_5_delta_38.csv   75_et_100_C_5_delta_83.csv\n",
            "75_et_100_C_5_delta_39.csv   75_et_100_C_5_delta_84.csv\n",
            "75_et_100_C_5_delta_3.csv    75_et_100_C_5_delta_85.csv\n",
            "75_et_100_C_5_delta_40.csv   75_et_100_C_5_delta_86.csv\n",
            "75_et_100_C_5_delta_41.csv   75_et_100_C_5_delta_87.csv\n",
            "75_et_100_C_5_delta_42.csv   75_et_100_C_5_delta_88.csv\n",
            "75_et_100_C_5_delta_43.csv   75_et_100_C_5_delta_89.csv\n",
            "75_et_100_C_5_delta_44.csv   75_et_100_C_5_delta_8.csv\n",
            "75_et_100_C_5_delta_45.csv   75_et_100_C_5_delta_90.csv\n",
            "75_et_100_C_5_delta_46.csv   75_et_100_C_5_delta_91.csv\n",
            "75_et_100_C_5_delta_47.csv   75_et_100_C_5_delta_92.csv\n",
            "75_et_100_C_5_delta_48.csv   75_et_100_C_5_delta_93.csv\n",
            "75_et_100_C_5_delta_49.csv   75_et_100_C_5_delta_94.csv\n",
            "75_et_100_C_5_delta_4.csv    75_et_100_C_5_delta_95.csv\n",
            "75_et_100_C_5_delta_50.csv   75_et_100_C_5_delta_96.csv\n",
            "75_et_100_C_5_delta_51.csv   75_et_100_C_5_delta_97.csv\n",
            "75_et_100_C_5_delta_52.csv   75_et_100_C_5_delta_98.csv\n",
            "75_et_100_C_5_delta_53.csv   75_et_100_C_5_delta_99.csv\n",
            "75_et_100_C_5_delta_54.csv   75_et_100_C_5_delta_9.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTeZj2Z3eJwV",
        "colab_type": "text"
      },
      "source": [
        "Every experiment is repeated 100 times.\n",
        "\n",
        "Let's check the trace of one experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRwGpDEHeMkK",
        "colab_type": "code",
        "outputId": "9a4332d0-8364-43f1-ee81-7a96d3515725",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        }
      },
      "source": [
        "filename = \"BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_33.csv\"\n",
        "df = pd.read_csv(filename)\n",
        "df"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>100</th>\n",
              "      <th>25</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.00060</td>\n",
              "      <td>4.9907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.99982</td>\n",
              "      <td>9.9443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.00340</td>\n",
              "      <td>14.9910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.01250</td>\n",
              "      <td>19.9870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.09670</td>\n",
              "      <td>25.0280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.10830</td>\n",
              "      <td>29.9820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.27700</td>\n",
              "      <td>35.3180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.27810</td>\n",
              "      <td>39.9750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1.24280</td>\n",
              "      <td>44.5390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1.42630</td>\n",
              "      <td>50.0520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1.44800</td>\n",
              "      <td>54.8200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1.33250</td>\n",
              "      <td>59.9640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1.39210</td>\n",
              "      <td>65.1400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1.57500</td>\n",
              "      <td>70.8650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1.50830</td>\n",
              "      <td>75.2580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1.49620</td>\n",
              "      <td>80.2280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1.68820</td>\n",
              "      <td>85.9380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1.81020</td>\n",
              "      <td>90.3930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1.76140</td>\n",
              "      <td>95.4080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1.73000</td>\n",
              "      <td>100.1100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        100        25\n",
              "0   1.00060    4.9907\n",
              "1   0.99982    9.9443\n",
              "2   1.00340   14.9910\n",
              "3   1.01250   19.9870\n",
              "4   1.09670   25.0280\n",
              "5   1.10830   29.9820\n",
              "6   1.27700   35.3180\n",
              "7   1.27810   39.9750\n",
              "8   1.24280   44.5390\n",
              "9   1.42630   50.0520\n",
              "10  1.44800   54.8200\n",
              "11  1.33250   59.9640\n",
              "12  1.39210   65.1400\n",
              "13  1.57500   70.8650\n",
              "14  1.50830   75.2580\n",
              "15  1.49620   80.2280\n",
              "16  1.68820   85.9380\n",
              "17  1.81020   90.3930\n",
              "18  1.76140   95.4080\n",
              "19  1.73000  100.1100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgpozAfk8YZv",
        "colab_type": "text"
      },
      "source": [
        "The header is not a sample. It just tells us the scenario, i.e. total channel capacity (Mbps) and available bandwith (Mbps).\n",
        "\n",
        "The columns are:\n",
        "* $g_\\text{in} / g_\\text{ack}$\n",
        "* Some sort of time stamp that we will ignore (not well described in the dataset)\n",
        "\n",
        "Let's rename the columns to avoid ambiguity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hj41JABXM355",
        "colab_type": "code",
        "outputId": "80c8876c-76cf-41c6-dd4d-015fbbc9b83e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "df.columns=['gap_ratio', 'timestamp']\n",
        "df.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gap_ratio</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.00060</td>\n",
              "      <td>4.9907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.99982</td>\n",
              "      <td>9.9443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.00340</td>\n",
              "      <td>14.9910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.01250</td>\n",
              "      <td>19.9870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.09670</td>\n",
              "      <td>25.0280</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   gap_ratio  timestamp\n",
              "0    1.00060     4.9907\n",
              "1    0.99982     9.9443\n",
              "2    1.00340    14.9910\n",
              "3    1.01250    19.9870\n",
              "4    1.09670    25.0280"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bv8RhycEQsDM",
        "colab_type": "text"
      },
      "source": [
        "# Feature engineering\n",
        "\n",
        "Each experiment will be a sample.\n",
        "\n",
        "The features of a sample are the elements of the histogram of the first column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFbGLRg6NfSM",
        "colab_type": "code",
        "outputId": "5053b62e-97f4-4994-aca5-70e790838a69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "plt.hist(df['gap_ratio'], density=True)\n",
        "\n",
        "# density:  True garantees that the area is 1 (such that hist approximates a \n",
        "#                 probability densitplt.hist(x)y function)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([2.46797799, 1.23398899, 0.6169945 , 1.23398899, 1.23398899,\n",
              "        1.23398899, 1.23398899, 0.6169945 , 0.6169945 , 1.85098349]),\n",
              " array([0.99982 , 1.080858, 1.161896, 1.242934, 1.323972, 1.40501 ,\n",
              "        1.486048, 1.567086, 1.648124, 1.729162, 1.8102  ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGmGhS1Ij/hfxNYmhR1D1zQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cncq7wY4PkDR",
        "colab_type": "text"
      },
      "source": [
        "However, the sequence of bins is chosen automatically by `matplotlib` and may change from an experiment to another.\n",
        "\n",
        "We need instead to describe all the experiments with a uniform set of features => The sequence of bins must be the same for all the experiments.\n",
        "\n",
        "To do so:\n",
        "* Open all files\n",
        "* Take the min and max gap from all the experiments\n",
        "* Divide the [min,max] interval uniformly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcGA9B5LQaSE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_all_csv_files(folder):\n",
        "  \"\"\"\n",
        "  Credits to https://perials.com/getting-csv-files-directory-subdirectories-using-python/\n",
        "\n",
        "  Returns all the csv files within the folder, and all subfolders\n",
        "  \"\"\"\n",
        "  import os\n",
        "  from glob import glob\n",
        "  PATH = \"/home/someuser/projects/someproject\"\n",
        "  EXT = \"*.csv\"\n",
        "  all_csv_files = [file\n",
        "                  for path, subdir, files in os.walk(folder)\n",
        "                  for file in glob(os.path.join(path, \"*.csv\"))]\n",
        "  return all_csv_files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jpmcIZJ5yGu",
        "colab_type": "text"
      },
      "source": [
        "To avoid data leaks, we compute the max and the min on the training set only."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DjjYN6d54T0",
        "colab_type": "code",
        "outputId": "76a3b47d-dd77-4077-85ac-0d176c605d7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_files = get_all_csv_files('BandwidthEstimationTraces/training')\n",
        "print('Found ', len(train_files), ' training files' )"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found  1100  training files\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laMuRhZqv6dR",
        "colab_type": "text"
      },
      "source": [
        "Find the min and max"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWFro1CZkRua",
        "colab_type": "code",
        "outputId": "cad2f255-7cff-49d4-f762-f94d4713c501",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "min_gap = float('inf')\n",
        "max_gap = 0\n",
        "\n",
        "for filename in train_files:\n",
        "      df = pd.read_csv(filename)\n",
        "      df.columns=['gap_ratio', 'timestamp']\n",
        "      trace_min = min( df['gap_ratio'] )\n",
        "      trace_max = max( df['gap_ratio'] )\n",
        "      min_gap = min ( [ min_gap, trace_min ] )\n",
        "      max_gap = max ( [ max_gap, trace_max ] )\n",
        "\n",
        "print('min_gap:', min_gap, ' max_gap:',max_gap)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "min_gap: 0.95975  max_gap: 2.318\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cS7y7cT-XmpQ",
        "colab_type": "text"
      },
      "source": [
        "Let's create the bins that we will use for all experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPnUK2tiXuEB",
        "colab_type": "code",
        "outputId": "2f206c3a-7653-49a1-ec60-c99148680e72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        }
      },
      "source": [
        "N = 8 # num of bins\n",
        "\n",
        "bin_size = (max_gap-min_gap)/N \n",
        "bins = [min_gap + i * bin_size for i in range(0, N+1)]\n",
        "bins"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.95975,\n",
              " 1.1295312499999999,\n",
              " 1.2993125,\n",
              " 1.4690937499999999,\n",
              " 1.638875,\n",
              " 1.8086562499999999,\n",
              " 1.9784375,\n",
              " 2.14821875,\n",
              " 2.318]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atGuyYNKYR-1",
        "colab_type": "text"
      },
      "source": [
        "Just as a visual check, let's plot again the previous histogram with these new bins"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWkFTXN0YWH2",
        "colab_type": "code",
        "outputId": "733f30f1-6b22-4372-ce0b-629a04b64cae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "filename = \"BandwidthEstimationTraces/training/SingleLinkCapacity100/75_et_100_C_5_delta/75_et_100_C_5_delta_33.csv\"\n",
        "df = pd.read_csv(filename)\n",
        "df.columns=['gap_ratio', 'timestamp']\n",
        "hist_values, bins, bars = plt.hist( df['gap_ratio'], density=True, bins=bins)\n",
        "print(hist_values )"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.76697957 0.88348978 1.17798638 0.88348978 0.88348978 0.29449659\n",
            " 0.         0.        ]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyjd51oBcD8n",
        "colab_type": "text"
      },
      "source": [
        "Let's obtain the histogram for all the experiments. For each experiment, we construct a feature vector:\n",
        "\n",
        "  `[bin1_freq, bin2_freq, ...., binN_freq]`\n",
        "\n",
        "and a label `avail_bandwidth`.\n",
        "\n",
        "We write these operations in a function `construct_dataset` that we will then use for the training and the test dataset.\n",
        "\n",
        "This is to avoid **copied and pasted code**, which are error prone."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCEHvKgTaGjN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_file(filename, bins):\n",
        "      \"\"\"\n",
        "      For the connection described in filename, it\n",
        "      returns a feature vector and the available bandwidth\n",
        "      \"\"\"\n",
        "      df = pd.read_csv(filename)\n",
        "\n",
        "      # Observe that for each experiment, the available bandwidth corresponds \n",
        "      # to the name of the second column\n",
        "      avail_band = df.columns[1]\n",
        "\n",
        "\n",
        "      df.columns=['gap_ratio', 'timestamp']\n",
        "\n",
        "      histogram_values, bins, bars = plt.hist( df['gap_ratio'], density=True, \n",
        "                                              bins=bins)\n",
        "\n",
        "      return histogram_values, avail_band\n",
        "\n",
        "\n",
        "\n",
        "def construct_dataset(files, bins):\n",
        "  \"\"\"\n",
        "  Build an X,y from the files\n",
        "  \"\"\"\n",
        "\n",
        "  X = np.empty((0,N), int)\n",
        "  label = []\n",
        "\n",
        "  for filename in files:\n",
        "      histogram_values, avail_band = process_file(filename, bins)\n",
        "\n",
        "      X = np.vstack(( X, histogram_values) )\n",
        "      label.append(avail_band)\n",
        "\n",
        "  return X,label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6Ekap9q-_ia",
        "colab_type": "code",
        "outputId": "42ae56e3-51ca-4f32-f2b2-83568c7ff95c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "X_train_raw, label_train_raw = construct_dataset(train_files, bins)\n",
        "\n",
        "test_files = get_all_csv_files('BandwidthEstimationTraces/testing')\n",
        "print ('Found ', len(test_files), ' test files'  )\n",
        "\n",
        "X_test, label_test = construct_dataset(test_files, bins)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found  1000  test files\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAMSElEQVR4nO3da4xcBRnG8eexrQGlEWJHJCx1CfEC\nUYG6IpF78UIrkRhJABESYrKiaEpCIpUPovFL+SASI4ibQvCCoJGCSAQltKUl2OIWC72skIqABUy3\noNxMJKWvH2ZKy+bMztl2zpx32P8v2TDLnA5PNjv/nA5zdh0RAgDk9ba6BwAAJkeoASA5Qg0AyRFq\nAEiOUANAcjOreNA5c+bE4OBgFQ8NAG9J69at2x4RjaL7Kgn14OCgRkdHq3hoAHhLsv1Uu/t46QMA\nkiPUAJAcoQaA5Ag1ACRHqAEgOUINAMkRagBIjlADQHKEGgCSq+TKxH2xdfHquicUGlhyUt0TAExT\nnFEDQHKEGgCSI9QAkByhBoDkCDUAJEeoASA5Qg0AyRFqAEiOUANAcoQaAJJLdwn5wH5n1j2hjRfr\nHgBgmuKMGgCSI9QAkByhBoDkCDUAJEeoASA5Qg0AyRFqAEiu1PuobT8p6WVJr0vaERFDVY4CAOw2\nlQteTouI7ZUtAQAU4qUPAEiu7Bl1SPqT7ZD004gYmXiA7WFJw5I0d+7cvR70kcP3/s9WaUPdAwBM\nW2XPqE+MiHmSFki6xPbJEw+IiJGIGIqIoUaj0dWRADCdlQp1RDzT+uc2SbdLOq7KUQCA3TqG2vY7\nbc/edVvSZyRtrHoYAKCpzGvUB0u63fau438VEfdUugoA8IaOoY6IJyQd3YMtAIACvD0PAJIj1ACQ\nHKEGgOQINQAkl+6X247P/UXdEwAgFc6oASA5Qg0AyRFqAEiOUANAcoQaAJIj1ACQHKEGgOQINQAk\nR6gBIDlCDQDJEWoASI5QA0ByhBoAkiPUAJAcoQaA5Ag1ACRHqAEgOUINAMkRagBIjlADQHKEGgCS\nI9QAkByhBoDkSofa9gzbf7V9V5WDAABvNpUz6kWSxqoaAgAoVirUtgckfU7S0mrnAAAmKntGfY2k\nb0na2e4A28O2R22Pjo+Pd2UcAKBEqG2fKWlbRKyb7LiIGImIoYgYajQaXRsIANNdmTPqEyR93vaT\nkm6VNN/2LytdBQB4Q8dQR8S3I2IgIgYlnStpeUR8ufJlAABJvI8aANKbOZWDI2KlpJWVLAEAFOKM\nGgCSI9QAkByhBoDkCDUAJEeoASA5Qg0AyRFqAEiOUANAcoQaAJIj1ACQHKEGgOQINQAkR6gBIDlC\nDQDJEWoASI5QA0ByhBoAkiPUAJAcoQaA5Ag1ACRHqAEgOUINAMkRagBIjlADQHKEGgCSI9QAkByh\nBoDkCDUAJNcx1Lb3s/2Q7Udsb7L9vV4MAwA0zSxxzP8kzY+IV2zPkvSA7bsjYk3F2wAAKhHqiAhJ\nr7Q+ndX6iCpHAQB2K/Uate0ZttdL2ibp3ohYW3DMsO1R26Pj4+Pd3gkA01apUEfE6xFxjKQBScfZ\n/nDBMSMRMRQRQ41Go9s7AWDamtK7PiLiP5JWSDqjmjkAgInKvOujYfvA1u39JX1a0t+qHgYAaCrz\nro9DJP3M9gw1w/6biLir2lkAgF3KvOvjUUnH9mALAKAAVyYCQHKEGgCSI9QAkByhBoDkCDUAJEeo\nASA5Qg0AyRFqAEiOUANAcoQaAJIj1ACQHKEGgOQINQAkR6gBIDlCDQDJEWoASI5QA0ByhBoAkivz\nOxMh6b7lR9Q9odDp8/9e9wQAFeOMGgCSI9QAkByhBoDkCDUAJEeoASA5Qg0AyRFqAEiOUANAcoQa\nAJLrGGrbh9leYXuz7U22F/ViGACgqcwl5DskXRYRD9ueLWmd7XsjYnPF21DCD845s+4JhS779V11\nTwDeMjqeUUfEcxHxcOv2y5LGJB1a9TAAQNOUXqO2PSjpWElrC+4btj1qe3R8fLw76wAA5UNt+wBJ\nt0m6NCJemnh/RIxExFBEDDUajW5uBIBprVSobc9SM9I3R8SyaicBAPZU5l0flnSDpLGIuLr6SQCA\nPZU5oz5B0gWS5tte3/pYWPEuAEBLx7fnRcQDktyDLQCAAlyZCADJEWoASI5fblvS6au21z2h0KUL\nn6p7QqFzFq+ue0JfGVhyUt0TkBhn1ACQHKEGgOQINQAkR6gBIDlCDQDJEWoASI5QA0ByhBoAkiPU\nAJAcoQaA5LiEvKT3nnJ/3RMKrfjaeXVPKLT03PvqntBXrl8xu+4Jhf512jF1T4A4owaA9Ag1ACRH\nqAEgOUINAMkRagBIjlADQHKEGgCSI9QAkByhBoDkCDUAJMcl5H3u2eteq3tCoe+u+mHdEwpl/VEA\nF99/R90TinEJeQqcUQNAcoQaAJIj1ACQXMdQ277R9jbbG3sxCADwZmXOqG+SdEbFOwAAbXQMdUSs\nkvRCD7YAAAp07TVq28O2R22Pjo+Pd+thAWDa61qoI2IkIoYiYqjRaHTrYQFg2uNdHwCQHKEGgOQ6\nXkJu+xZJp0qaY3urpCsj4oaqh6Gc831b3ROKnVL3gP4ye2y07gmFrr14ed0TCl1y/fy6J/RUx1BH\nxHm9GAIAKMZLHwCQHKEGgOQINQAkR6gBIDlCDQDJEWoASI5QA0ByhBoAkiPUAJAcv4W8z90cX6x7\nQqG0l7ZjSuavvKTuCW2M1T2gpzijBoDkCDUAJEeoASA5Qg0AyRFqAEiOUANAcoQaAJIj1ACQHKEG\ngOQINQAkxyXkmFayXnKvr9Y9oNiRq7bXPaHQ1sWr655QaGDJSZU8LmfUAJAcoQaA5Ag1ACRHqAEg\nOUINAMkRagBIjlADQHKlQm37DNuP2d5ie3HVowAAu3UMte0Zkq6VtEDSUZLOs31U1cMAAE1lzqiP\nk7QlIp6IiNck3SrprGpnAQB2KXMJ+aGS/rnH51slfWLiQbaHJQ23Pn3F9mP7Pq+tOZJyXtvaXiWb\nP9XtB9xtH/ce27UhU9Bxc4Vfr73F9/JeOXmqf6A3m6/apz/9vnZ3dO1nfUTEiKSRbj3eZGyPRsRQ\nL/5b3dJvm/ttr8TmXmFz75V56eMZSYft8flA698BAHqgTKj/Iun9tg+3/XZJ50q6s9pZAIBdOr70\nERE7bH9D0h8lzZB0Y0RsqnzZ5HryEkuX9dvmftsrsblX2Nxjjoi6NwAAJsGViQCQHKEGgOTShtr2\njba32d7Y5n7b/lHrsvZHbc/r9caCTZ02n9/ausH2g7aP7vXGgk2Tbt7juI/b3mH77F5ta7Oj417b\np9peb3uT7ft7ua/Nnk7fF++y/Xvbj7Q2X9TrjQWbDrO9wvbm1qZFBcekeQ6W3Jvu+VdaRKT8UPMd\n7fMkbWxz/0JJd0uypOMlre2DzZ+UdFDr9oJ+2Nw6Zoak5ZL+IOnszHslHShps6S5rc/fk/1rLOkK\nSVe1bjckvSDp7TVvPkTSvNbt2ZIel3TUhGPSPAdL7k33/Cv7kfaMOiJWqfkN285Zkn4eTWskHWj7\nkN6sK9Zpc0Q8GBH/bn26Rs33pNeqxNdZkr4p6TZJ26pfNLkSe78kaVlEPN06vh82h6TZti3pgNax\nO3qxre2giOci4uHW7Zcljal5lfKe0jwHy+zN+PwrK22oSyi6tH3iN1JmX1HzbCQ124dK+oKkn9S9\npaQPSDrI9krb62xfWPegEn4s6UhJz0raIGlRROysd9JutgfV/JkAayfclfI5OMnePfXF82+Xrl1C\njvJsn6bmN8qJdW8p4RpJl0fEzuYJX3ozJX1M0umS9pf0Z9trIuLxemdN6rOS1kuaL+kISffaXh0R\nL9U7S7J9gJp/m7o0w55Oyuzts+efpP4OdV9e2m77o5KWSloQEc/XvaeEIUm3tiI9R9JC2zsi4o56\nZ7W1VdLzEfGqpFdtr5J0tJqvWWZ1kaQl0XzxdIvtf0j6kKSH6hxle5aa0bs5IpYVHJLqOVhibz8+\n/yT190sfd0q6sPV/no+X9GJEPFf3qMnYnitpmaQLkp/hvSEiDo+IwYgYlPRbSV9PHGlJ+p2kE23P\ntP0ONX/S41jNmzp5Ws2/Acj2wZI+KOmJOge1Xi+/QdJYRFzd5rA0z8Eye/vx+bdL2jNq27dIOlXS\nHNtbJV0paZYkRcT1ar4DYaGkLZL+q+ZZSa1KbP6OpHdLuq51hrojav6JXiU2p9Jpb0SM2b5H0qOS\ndkpaGhGTvvWwaiW+xt+XdJPtDWq+g+LyiKj7R5+eIOkCSRtsr2/9uyskzZVSPgfL7E33/CuLS8gB\nILl+fukDAKYFQg0AyRFqAEiOUANAcoQaAJIj1ACQHKEGgOT+D74bqEvrI9ApAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STsxNvnVB-ZN",
        "colab_type": "code",
        "outputId": "2634ebd0-b92b-410b-f51f-b52eb970067b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "source": [
        "print('X_train\\n', X_train_raw[0:6, :] )\n",
        "print('\\n\\nlabel_train\\n',label_train_raw )"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train\n",
            " [[2.94496595 1.17798638 1.17798638 0.58899319 0.         0.\n",
            "  0.         0.        ]\n",
            " [3.23946254 0.58899319 0.88348978 0.29449659 0.58899319 0.29449659\n",
            "  0.         0.        ]\n",
            " [3.23946254 0.88348978 0.29449659 0.58899319 0.58899319 0.29449659\n",
            "  0.         0.        ]\n",
            " [3.23946254 0.58899319 0.58899319 0.88348978 0.29449659 0.29449659\n",
            "  0.         0.        ]\n",
            " [2.94496595 1.17798638 0.58899319 0.58899319 0.58899319 0.\n",
            "  0.         0.        ]\n",
            " [2.94496595 1.17798638 0.58899319 0.58899319 0.29449659 0.29449659\n",
            "  0.         0.        ]]\n",
            "\n",
            "\n",
            "label_train\n",
            " ['25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '50', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '75', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '25', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '12.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5', '37.5']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwqgnS9lKLFp",
        "colab_type": "text"
      },
      "source": [
        "### Class imbalance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03Tclu74Kbi5",
        "colab_type": "text"
      },
      "source": [
        "Let's check for class imbalance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugBoY1tB8gG9",
        "colab_type": "code",
        "outputId": "05ca0769-0aa6-438e-e99d-39af1ba3c8a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "Counter(label_train_raw)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'12.5': 100, '25': 400, '37.5': 100, '50': 400, '75': 100})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJkz2kra9rDP",
        "colab_type": "text"
      },
      "source": [
        "Correct using Synthetic Minority Over-Sampling Technique (SMOTE) (see `03.classification.ipynb`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toS5Tgne-lnN",
        "colab_type": "code",
        "outputId": "77554f15-74ff-437c-dfc8-7c06c79e7656",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "smote = SMOTE()\n",
        "X_train, label_train = smote.fit_sample(X_train_raw, label_train_raw)\n",
        "\n",
        "Counter(label_train)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'12.5': 400, '25': 400, '37.5': 400, '50': 400, '75': 400})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K03VxUJ1idJp",
        "colab_type": "text"
      },
      "source": [
        "### Scaling\n",
        "With NN is important to **scale** the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CpWt6qKivif",
        "colab_type": "code",
        "outputId": "5afe6567-1ef4-482d-cf29-dbea1689869f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        }
      },
      "source": [
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "print('X_train scaled\\n', X_train[0:6, :] )"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train scaled\n",
            " [[0.46666667 0.5        0.57142857 0.33333333 0.         0.\n",
            "  0.         0.        ]\n",
            " [0.53333333 0.25       0.42857143 0.16666667 0.33333333 0.2\n",
            "  0.         0.        ]\n",
            " [0.53333333 0.375      0.14285714 0.33333333 0.33333333 0.2\n",
            "  0.         0.        ]\n",
            " [0.53333333 0.25       0.28571429 0.5        0.16666667 0.2\n",
            "  0.         0.        ]\n",
            " [0.46666667 0.5        0.28571429 0.33333333 0.33333333 0.\n",
            "  0.         0.        ]\n",
            " [0.46666667 0.5        0.28571429 0.33333333 0.16666667 0.2\n",
            "  0.         0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAY-VQMf80Nf",
        "colab_type": "text"
      },
      "source": [
        "### One-hot encoding\n",
        "**One-hot encode** the target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZWAb6fb_lMv",
        "colab_type": "code",
        "outputId": "e54d3d61-ec8f-4457-c23f-00a9055337f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "# OneHotEncoder works best with dataframes. Let's convert our y lists to \n",
        "# dataframes\n",
        "label_train_df = pd.DataFrame({'label':label_train})\n",
        "label_test_df = pd.DataFrame({'label':label_test})\n",
        "\n",
        "label_train_df"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     label\n",
              "0       25\n",
              "1       25\n",
              "2       25\n",
              "3       25\n",
              "4       25\n",
              "...    ...\n",
              "1995    75\n",
              "1996    75\n",
              "1997    75\n",
              "1998    75\n",
              "1999    75\n",
              "\n",
              "[2000 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_iC8vrtk3uE",
        "colab_type": "code",
        "outputId": "5dbdb06d-afc1-427f-fa5c-ebfd229ee64c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "source": [
        "one_hot_encoder = ce.OneHotEncoder(cols=['label'], use_cat_names='True')\n",
        "one_hot_encoder.fit(label_train_df)\n",
        "y_train = one_hot_encoder.transform(label_train_df)\n",
        "y_test  = one_hot_encoder.transform(label_test_df)\n",
        "\n",
        "print('y_train', y_train)\n",
        "\n",
        "num_of_classes = y_train.shape[1]\n",
        "class_names = y_train.columns\n",
        "print('There are ', num_of_classes, ' classes:', class_names)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y_train       label_25  label_50  label_75  label_12.5  label_37.5\n",
            "0            1         0         0           0           0\n",
            "1            1         0         0           0           0\n",
            "2            1         0         0           0           0\n",
            "3            1         0         0           0           0\n",
            "4            1         0         0           0           0\n",
            "...        ...       ...       ...         ...         ...\n",
            "1995         0         0         1           0           0\n",
            "1996         0         0         1           0           0\n",
            "1997         0         0         1           0           0\n",
            "1998         0         0         1           0           0\n",
            "1999         0         0         1           0           0\n",
            "\n",
            "[2000 rows x 5 columns]\n",
            "There are  5  classes: Index(['label_25', 'label_50', 'label_75', 'label_12.5', 'label_37.5'], dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsDxd9KuCnzg",
        "colab_type": "text"
      },
      "source": [
        "# Build a NN model\n",
        "\n",
        "To train faster, change the runtime to GPU.\n",
        "\n",
        "Now, let's build a NN architecture. The size of each sample is:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLRGAHB2oPJJ",
        "colab_type": "code",
        "outputId": "7d9d4252-8032-4a90-f25f-cada498639dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sample_size = X_train.shape[1]\n",
        "print('The sample size is ', sample_size, \n",
        "      ', which should correspond to the number of bins ', N)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The sample size is  8 , which should correspond to the number of bins  8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9aa9XrBoFAm",
        "colab_type": "text"
      },
      "source": [
        "Let's fix the learning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEIxDxPXoKNb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_rate = 0.01"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PTmksjnoM3k",
        "colab_type": "text"
      },
      "source": [
        "Let's write a function to build a model. We need to:\n",
        "* Define the architecture\n",
        "* Compile it, i.e., decide the loss function to minimize, the optimization function and the metrics to show"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0zcfeTEC0KF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "  # Reproducibility: to ensure every time we generate a model, its weights are \n",
        "  #     always initialized in the same way\n",
        "  # To know more: \n",
        "  #       https://machinelearningmastery.com/reproducible-results-neural-networks-keras/\n",
        "  np.random.seed(6)\n",
        "  tf.random.set_seed(4)\n",
        "\n",
        "\n",
        "\n",
        "  model = Sequential([\n",
        "    Dense(200, input_dim=sample_size, activation='relu' ),\n",
        "    Dense(50, input_dim=sample_size, activation='relu' ),\n",
        "    Dense(30, input_dim=sample_size, activation='relu' ),\n",
        "    Dense(15, input_dim=sample_size, activation='relu' ),\n",
        "    Dense(8, input_dim=sample_size, activation='relu' ),\n",
        "    Dense(num_of_classes, activation=\"softmax\")\n",
        "  ])\n",
        "  # The first layer has 4 neurons and take 8 input values.\n",
        "  # In the first layer, you always need to specify the input_dim\n",
        "  #\n",
        "  # Note that each layer adds implicitly a bias term (we do not need to care about \n",
        "  # it)\n",
        "  #\n",
        "  # The last layer is a softmax, since we are doing classification\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  model.compile(loss=\"categorical_crossentropy\", \n",
        "              optimizer=keras.optimizers.SGD(lr=learn_rate) ,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0SfFwbExxs9",
        "colab_type": "text"
      },
      "source": [
        "See Ch.10 of [Ge19] to know more about these hyper-parameters.\n",
        "\n",
        "Loss function:\n",
        "* `categorical_crossentropy` is the cross-entropy as we defined in the slides\n",
        "* In binary classification then use `sigmoid` activation function in the output layer instead of the `softmax` and `binary_crossentropy` loss.\n",
        "\n",
        "Optimizer:\n",
        "* We are using Stochastic Gradient Descent with learning rate $\\eta=$ `learn_rate`\n",
        "\n",
        "Metrics:\n",
        "* We are asking Keras to show at each epoch the accuracy. Note that the accuracy value is ignored during training. This metric is just visualized"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VugALgbowkG",
        "colab_type": "text"
      },
      "source": [
        "Let's build a model and print its description"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0eA8qTowf16",
        "colab_type": "code",
        "outputId": "bfb6414c-f5bc-40e9-9e12-522e034b9ff4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = build_model()\n",
        "model.summary()\n",
        "plot_model(model)\n",
        "\n",
        "\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 200)               1800      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 50)                10050     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 30)                1530      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 15)                465       \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 8)                 128       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 5)                 45        \n",
            "=================================================================\n",
            "Total params: 14,018\n",
            "Trainable params: 14,018\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAN0AAAKECAIAAAAMuKhbAAAABmJLR0QA/wD/AP+gvaeTAAAgAElE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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2j9Me58Jk93",
        "colab_type": "text"
      },
      "source": [
        "This network is probably too big with respect to the small amount of data. However, nobody can tell us, until we see the training results.\n",
        "\n",
        "**Always experiment with NNs of different sizes**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AZY1xtwl0jq",
        "colab_type": "text"
      },
      "source": [
        "# Training\n",
        "\n",
        "To train faster, change the runtime to GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAPBL60-pddu",
        "colab_type": "code",
        "outputId": "ca05a8a3-2c18-43ca-c51d-36d4013ff350",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "history = model.fit(X_train, y_train, epochs=10, validation_split=0.2)\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 1.5870 - accuracy: 0.2731 - val_loss: 1.6396 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 1.5445 - accuracy: 0.3038 - val_loss: 1.6769 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 1.5061 - accuracy: 0.3069 - val_loss: 1.7177 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 1.4678 - accuracy: 0.3444 - val_loss: 1.7658 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 1.4289 - accuracy: 0.4906 - val_loss: 1.8157 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 1.3885 - accuracy: 0.5238 - val_loss: 1.8742 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 1.3500 - accuracy: 0.5362 - val_loss: 1.9274 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 1.3132 - accuracy: 0.5481 - val_loss: 1.9748 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "50/50 [==============================] - 2s 33ms/step - loss: 1.2782 - accuracy: 0.5663 - val_loss: 2.0332 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 1.2445 - accuracy: 0.5794 - val_loss: 2.0619 - val_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xebwBVml9sSw",
        "colab_type": "text"
      },
      "source": [
        "We divide the training set in two subsets:\n",
        "* The training subset\n",
        "* The validation subset \n",
        "\n",
        "Keras:\n",
        "* Minimizes the loss on the training subset\n",
        "* The validation subset is ignored => No impact on training\n",
        "* The validation subset is just used to check overfitting:\n",
        "    * If validation loss starts to increase\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBRB-Ofm6gWG",
        "colab_type": "code",
        "outputId": "1613326d-7c1a-43d5-8321-9c5946e539ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(label_train)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['25' '25' '25' ... '75' '75' '75']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwDQU9pa6sjC",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**Note** Keras divides the trainining set in two consecutive parts \n",
        "\n",
        "==> Need to shuffle data first\n",
        "\n",
        "_Attention_ `model.fit(..)` has a parameter `shuffle`, but it still divides training and validation subset consecutively, just it shuffles the training subset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_Y4xLk75lH_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, y_train, label_train = shuffle(X_train, y_train,label_train, \n",
        "                                        random_state=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Je9WQ_Si-Xt0",
        "colab_type": "code",
        "outputId": "1cc5fa03-4759-405b-e0ad-0d0ac36b86b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(label_train)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['12.5' '37.5' '12.5' ... '12.5' '37.5' '75']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToEr6OsEpvi7",
        "colab_type": "text"
      },
      "source": [
        "We can add some useful operations to training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jIuLvmiq4rt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(nn_file, X_tr, y_tr, epochs, overwrite=False):\n",
        "  \"\"\"\n",
        "  nn_file:  Before training, the model contained in this file will be loaded\n",
        "            After training, the resulting model will be written in this file\n",
        "\n",
        "  \n",
        "  overwrite: If true, the model will be built and trained from scratch\n",
        "  \"\"\"\n",
        "  \n",
        "  ##################\n",
        "  #### CALLBACKS ###\n",
        "  ##################\n",
        "  # These functions are called at every epoch\n",
        "  plot_cb = PlotLossesKeras()  # Plots the loss\n",
        "  checkpoint_cb = ModelCheckpoint(nn_file) # Stores weights\n",
        "  logger_cb = CSVLogger(nn_file+'.csv', append=True) # Stores history\n",
        "                # see https://theailearner.com/2019/07/23/keras-callbacks-csvlogger/\n",
        "\n",
        "\n",
        "\n",
        "  if overwrite==True:\n",
        "    os.remove(nn_file)\n",
        "    os.remove(nn_file+'.csv')\n",
        "\n",
        "\n",
        "  if not isfile(nn_file):\n",
        "    model = build_model()\n",
        "  else:\n",
        "    model = load_model(nn_file)\n",
        "\n",
        "  history = model.fit(X_tr, y_tr, epochs=epochs, \n",
        "                      callbacks = [plot_cb, checkpoint_cb, logger_cb], \n",
        "                      validation_split=0.2 )\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAqp2x0EvexH",
        "colab_type": "code",
        "outputId": "f4620143-bdd5-47ad-b278-34a446c4a85b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 916
        }
      },
      "source": [
        "nn_file = my_path + 'nn1.h5'\n",
        "\n",
        "model = train_model(nn_file, X_train, y_train, epochs=20)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-fe0888f4a44f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnn_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'nn1.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-35-a8ffa814b244>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(nn_file, X_tr, y_tr, epochs, overwrite)\u001b[0m\n\u001b[1;32m     31\u001b[0m   history = model.fit(X_tr, y_tr, epochs=epochs, \n\u001b[1;32m     32\u001b[0m                       \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mplot_cb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_cb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger_cb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                       validation_split=0.2 )\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    761\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m             steps=data_handler.inferred_steps)\n\u001b[0m\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, callbacks, add_history, add_progbar, model, **params)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     self._should_call_train_batch_hooks = any(\n\u001b[0;32m--> 231\u001b[0;31m         cb._implements_train_batch_hooks() for cb in self.callbacks)\n\u001b[0m\u001b[1;32m    232\u001b[0m     self._should_call_test_batch_hooks = any(\n\u001b[1;32m    233\u001b[0m         cb._implements_test_batch_hooks() for cb in self.callbacks)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     self._should_call_train_batch_hooks = any(\n\u001b[0;32m--> 231\u001b[0;31m         cb._implements_train_batch_hooks() for cb in self.callbacks)\n\u001b[0m\u001b[1;32m    232\u001b[0m     self._should_call_test_batch_hooks = any(\n\u001b[1;32m    233\u001b[0m         cb._implements_test_batch_hooks() for cb in self.callbacks)\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'PlotLossesCallback' object has no attribute '_implements_train_batch_hooks'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtToyIGtxY83",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.read_csv(nn_file+'.csv').head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ADD1Y_nxCcv",
        "colab_type": "text"
      },
      "source": [
        "Write a function to plot the training history"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVY854n8wSko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_train_hist(csv_hist_file):\n",
        "  hist_df = pd.read_csv(csv_hist_file)\n",
        "  hist_df[['acc', 'loss', 'val_acc', 'val_loss']].plot()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tc5dztcSxnQp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_train_hist(nn_file+'.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PsMSdYox7Gz",
        "colab_type": "text"
      },
      "source": [
        "Let's continue training the same model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z483MReLyOwz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = train_model(nn_file, X_train, y_train, epochs=30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWJCpnySyizx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_train_hist(nn_file+'.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQcQJQ0LyplW",
        "colab_type": "text"
      },
      "source": [
        "Observe that we have the entire history: the previous training and the latter toghether"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2u6u_E06zk4",
        "colab_type": "text"
      },
      "source": [
        "Let's train the model with more epochs\n",
        "\n",
        "The following is just a picture showing the results of continuing training.\n",
        "\n",
        "![alt text](https://raw.githubusercontent.com/andreaaraldo/machine-learning-for-networks/master/04.neural_networks/img/continuing_training.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6MF5hRQ6JGn",
        "colab_type": "text"
      },
      "source": [
        "Note that it seems validation loss is very instable. Don't worry, this is just the effect of zooming!\n",
        "\n",
        "Let's plot the entire training history."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZicBRnC6YXH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_train_hist(nn_file+'.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "---nY9f86zD3",
        "colab_type": "text"
      },
      "source": [
        "* The training loss stabilized ==> we can assume we have converged"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TG8TIN4zsKw",
        "colab_type": "text"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IADgsSbyEcUh",
        "colab_type": "text"
      },
      "source": [
        "Let's use the model for prediction. With next lines you get the probability of each sample being in a class and the predicted class (the one with the highest probability)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyiVCSF976Y0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = load_model(nn_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvWVnm5pG505",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_proba = model.predict(X_test)\n",
        "print( 'y_proba\\n', y_proba)\n",
        "\n",
        "pred_label = model.predict_classes(X_test)\n",
        "print( 'pred_label\\n', pred_label )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRDgFle0ByJ5",
        "colab_type": "text"
      },
      "source": [
        "The best metric is the confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9OReizvEXT5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HymnF9ty7RGX",
        "colab_type": "text"
      },
      "source": [
        "We need to convert one-hot-encoded values to numerical labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExiitzPmEDyE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "true_label = np.argmax(y_test.values, axis=1)\n",
        "true_label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtUXq83bB055",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_conf_mat(true_label, pred_label, np.array(class_names) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXPP66zQVXGF",
        "colab_type": "text"
      },
      "source": [
        "Some class does not appear in the matrix ==> no such class in the test set nor among the predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WlfFdI0VoZ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unique_labels(true_label, pred_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqsxRULREmZv",
        "colab_type": "text"
      },
      "source": [
        "If there are `nan`, it means that there is a label that does not appear in the test set but it is predicted by our model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjC05GoUEFZa",
        "colab_type": "text"
      },
      "source": [
        "We still need to improve. You can play with hyper-parameters (see slides):\n",
        "* Try simpler architectures\n",
        "* Try more complex architectures\n",
        "* Regularize\n",
        "* Change the batch size (default in `model.fit(..)` is 32)\n",
        "* Change the optimizer\n",
        "* Change the activation functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6u0cMK1JDKLH",
        "colab_type": "text"
      },
      "source": [
        "# Limitation of the work\n",
        "\n",
        "* Only a finite set of available bandwidth values are used (25, 50, 75 Mbps). In reality, any value can occur => Need to extend the test and validation test with random bandwidth values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EO57soSj0vmj",
        "colab_type": "text"
      },
      "source": [
        "# Regression\n",
        "\n",
        "To perform regression with neural network, you do the same things, just change the last layer: instead of `softmax`, it is just `Dense(1)` (see pagg. 307-308 of [Ge19])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VYbiDvHxLtU",
        "colab_type": "text"
      },
      "source": [
        "# References\n",
        "\n",
        "* [Ge19] Geron, Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2019, O'Reilly\n",
        "* [KhConf19] Khangura, S. K. (2019). Neural Network-based Available Bandwidth Estimation from TCP Sender-side Measurements. In IEEE/IFIP PEMWN.\n",
        "* [KhThesis19] Khangura, S. K. (2019). Machine Learning-based Available Bandwidth Estimation. Leibniz University."
      ]
    }
  ]
}