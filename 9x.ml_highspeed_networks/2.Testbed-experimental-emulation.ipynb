{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Testbed experimental emulation.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andreaaraldo/machine-learning-for-networks/blob/master/9x.ml_highspeed_networks/2.Testbed-experimental-emulation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrTjSwS6MMEl"
      },
      "source": [
        "from multiprocessing import Queue, Process, Event\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import queue\n",
        "import time\n",
        "import logging\n",
        "\n",
        "# The following is to be able to mount Google Drive\n",
        "from google.colab import drive\n",
        "\n",
        "import pickle # To load the model\n",
        "\n",
        "from tensorflow.keras.models import load_model"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aG0PV_TF-g4P"
      },
      "source": [
        "We connect Google Drive to load the model we trained in the other notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pl85JOuh-mej",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efb16d6f-64b2-418f-fcea-01d8070777ff"
      },
      "source": [
        "mount_point = '/content/gdrive' # Always the same, don't change it\n",
        "drive.mount(mount_point, force_remount=True)\n",
        "drive_path = mount_point + '/My Drive/' # Always the same, don't change it\n",
        "\n",
        "# Replace the following folder with some folder inside your google drive\n",
        "my_path = drive_path + \\\n",
        "  'tsp/teaching/data-science-for-networks/img-from-code/09.highspeed-net/'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hsExt5MEetZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8207a12a-ed15-485e-d26e-4165b14118b5"
      },
      "source": [
        "! wget https://raw.githubusercontent.com/andreaaraldo/machine-learning-for-networks/master/9x.ml_highspeed_networks/generator.csv"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-26 21:20:52--  https://raw.githubusercontent.com/andreaaraldo/machine-learning-for-networks/master/9x.ml_highspeed_networks/generator.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 176598 (172K) [text/plain]\n",
            "Saving to: ‘generator.csv’\n",
            "\n",
            "generator.csv       100%[===================>] 172.46K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2021-05-26 21:20:52 (10.1 MB/s) - ‘generator.csv’ saved [176598/176598]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6H9KDcVMMEy"
      },
      "source": [
        "After importing the main libraries, we can create a shared queue which simulates the physical link between two machines.\n",
        "\n",
        "\n",
        "TXGEN ---> [ shared queue ] ----> RX ----> Processing\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qcC7yA1MMEz"
      },
      "source": [
        "shared = Queue(maxsize=1024)   # Max size of the queue\n",
        "rate = .1 # inter-packet time;  Rate for the TX generation\n",
        "duration = 5"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rj0TxiHVMMFG"
      },
      "source": [
        "# TX gen function\n",
        "def txgen(id, l_queue, stop_event):\n",
        "    count= 0\n",
        "    lost = 0\n",
        "\n",
        "    # Read the tx dataset and transform to numpy\n",
        "    full_df = pd.read_csv('generator.csv')\n",
        "    data = full_df.to_numpy()\n",
        "    \n",
        "    # Limit to iterate over the dataset\n",
        "    # Feat to get rid of the labels in the csv\n",
        "    limit = len(data[:,0])\n",
        "    feat = len(data[0,:]) - 2\n",
        "    \n",
        "    while (not stop_event.is_set() ):\n",
        "#    while (total_number > 0 ):\n",
        "\n",
        "        try:\n",
        "            l_queue.put_nowait( data[count%limit,:feat] )\n",
        "            logging.debug(\"Packet added to the queue \" +str(count))\n",
        "        except queue.Full:\n",
        "            logging.debug(\"Packet loss!\")\n",
        "            lost += 1 \n",
        "\n",
        "\n",
        "        count += 1 \n",
        "        logging.debug(\"Total packet sent \" +str(count))\n",
        "        stop_event.wait(timeout=.00001)#        print (\"working on %s\" % arg)\n",
        "\n",
        "    logging.info(\"Sent: %d Lost %d \", count, lost)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jj9dWjiYMMFN"
      },
      "source": [
        "# PROCESSING FUNCTION: You have to modify this function\n",
        "# Hint: Import the traned model, perform the classification task, and then return\n",
        "def processing(element):\n",
        "\n",
        "    ##################################\n",
        "    # Your processing goes here\n",
        "    # after loading a model\n",
        "    # use it to process the element\n",
        "    #\n",
        "    # y_pred = model(element)\n",
        "    #\n",
        "    # You should return the value of the classification task y_pred\n",
        "    #  \n",
        "    # Bonus: You can also compare with the original y from the csv\n",
        "    ##################################\n",
        "\n",
        "    sample = element.reshape(-1,1).T\n",
        "    # predict_fun is to be defined later. Its implementation will depend on the\n",
        "    # model considered\n",
        "    y_pred = predict_fun(sample) \n",
        "\n",
        "\n",
        "    return (y_pred)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCRrCn83MMFV"
      },
      "source": [
        "# RX Function\n",
        "def rx(id, l_queue, stop_event):\n",
        "    logging.debug(\"Starting the consumer\")\n",
        "    count = 0\n",
        "\n",
        "    while (not stop_event.is_set()):\n",
        "\n",
        "        try:\n",
        "            logging.debug(\"Reading queue\")\n",
        "            pkt = l_queue.get(timeout=1)\n",
        "            logging.debug(\"Retrieved element\")\n",
        "\n",
        "            # Processing starting... First counter\n",
        "            #t0 = time.clock()\n",
        "            count+=1\n",
        "\n",
        "            #################################\n",
        "            # Processing function. Here you have to put your ML approach\n",
        "            # Pkt is already a numpy element, including all the features but no labels\n",
        "            # The processing task is to classify the pkt\n",
        "            processing(pkt)\n",
        "            #################################\n",
        "\n",
        "            #logging.debug(\"Elapsed time: %.6f\", time.clock() - t0)\n",
        "            logging.debug(\"Count: %d\", count)\n",
        "            \n",
        "        except Exception as e:\n",
        "            print (e)\n",
        "            pass\n",
        "    logging.info(\"Received: %d\", count)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GW-j3gSQMMFb"
      },
      "source": [
        "def main():\n",
        "    # Hint: use a global model loaded from the file where you saved your training model\n",
        "    \n",
        "    \n",
        "    # Event variables for the experiment\n",
        "    producer_stop = Event()\n",
        "    consumer_stop = Event()\n",
        "\n",
        "    # Logger: set the logger to level INFO for normal usage, DEBUG for detailed info\n",
        "    logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "    # Here we start the Traffic generator\n",
        "    t = Process(target=txgen, args=(0, shared, producer_stop))\n",
        "    t.start()\n",
        "\n",
        "    # Here we start the receiver\n",
        "    t2 = Process(target=rx, args=(0, shared, consumer_stop))\n",
        "    t2.start()\n",
        "\n",
        "    # Experiment duration\n",
        "    time.sleep(duration)\n",
        "    producer_stop.set()\n",
        "    time.sleep(1)\n",
        "    consumer_stop.set()\n",
        "\n",
        "    t.join()\n",
        "    t2.join()\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_oNCHyioNxq"
      },
      "source": [
        "# Before you continue\n",
        "\n",
        "It may happen that the `main()` goes on forever. We are sorry for this inconvenient. \n",
        "If this happens, on Google Colab:\n",
        "* Do \"Runtime > Factory Reset runtime\" and run again all the cells up to this current cell (\"Runtime > Run before\"). \n",
        "* Jump directly to the other model you want to try (do not run again a model you have already tried)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxNvj64kekPh"
      },
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XK1RXpUlFKjQ"
      },
      "source": [
        "Load your previously trained Logistic Regressor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MytIEB0eFMl3"
      },
      "source": [
        "# Replace with your filename\n",
        "with open(my_path+\"logistic-reg.pkl\", \"rb\") as dump_file:\n",
        "  model = pickle.load(dump_file)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m61nX1vZiamH"
      },
      "source": [
        "We need to define the predict function. This will be used inside the simulation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPT06Hg_iZRc"
      },
      "source": [
        "def predict_fun(sample):\n",
        "  y_pred = model.predict(sample)\n",
        "  return y_pred"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1gSmJy_etQQ"
      },
      "source": [
        "Let's run the simulation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iT5erIKVevp4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd864616-e3fc-4faa-bb87-4985134756f0"
      },
      "source": [
        "main()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:Sent: 32739 Lost 9139 \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:root:Received: 23600\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5OJswlYeyPZ"
      },
      "source": [
        "# Neural Network\n",
        "\n",
        "Scenario:\n",
        "inter-packet = 0.1\n",
        "\n",
        "queue-size = 1024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06tnHjt7dzxH"
      },
      "source": [
        "Let's now try with our previously trained neural network.\n",
        "We first load it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tW0TQAYmdyWT"
      },
      "source": [
        "nnfile = nn_file = my_path + 'nn1.h5'\n",
        "model = load_model(nn_file)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfX3ob4BkIgn"
      },
      "source": [
        "We redifine the prediction function. Note that the name of the function to predict in Keras is different than the scikit-learn models, like LogisticRegression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJFEm7TFjNog"
      },
      "source": [
        "def predict_fun(sample):\n",
        "  y_pred = np.argmax (model(sample, training=False) )\n",
        "  return y_pred"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZJcGRtNeTtk"
      },
      "source": [
        "We now run again the `main` function, this time model is this new one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmvClVgZeJcH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1e179b2-ea49-4661-f9ec-0d185384e73a"
      },
      "source": [
        "main()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:Sent: 44034 Lost 40445 \n",
            "INFO:root:Received: 3432\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFIQVdIalAwF"
      },
      "source": [
        "Observe that we lost a larger fraction of packets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCuUDRSre1Xc"
      },
      "source": [
        "# Your own models\n",
        "\n",
        "Try with other models (other NN architectures, other types of classifiers, etc.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTvm_xwEMMFo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}