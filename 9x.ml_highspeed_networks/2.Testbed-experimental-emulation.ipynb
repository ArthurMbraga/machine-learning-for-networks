{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Testbed experimental emulation.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andreaaraldo/machine-learning-for-networks/blob/master/9x.ml_highspeed_networks/2.Testbed-experimental-emulation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WrTjSwS6MMEl",
        "colab": {}
      },
      "source": [
        "from multiprocessing import Queue, Process, Event\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import queue\n",
        "import time\n",
        "import logging\n",
        "\n",
        "# The following is to be able to mount Google Drive\n",
        "from google.colab import drive\n",
        "\n",
        "import pickle # To load the model\n",
        "\n",
        "from tensorflow.keras.models import load_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aG0PV_TF-g4P",
        "colab_type": "text"
      },
      "source": [
        "We connect Google Drive to load the model we trained in the other notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pl85JOuh-mej",
        "colab_type": "code",
        "outputId": "440f3ba4-34dd-49cf-d30c-8807f8897571",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "mount_point = '/content/gdrive' # Always the same, don't change it\n",
        "drive.mount(mount_point, force_remount=True)\n",
        "drive_path = mount_point + '/My Drive/' # Always the same, don't change it\n",
        "\n",
        "# Replace the following folder with some folder inside your google drive\n",
        "my_path = drive_path + \\\n",
        "  'tsp/teaching/data-science-for-networks/img-from-code/09.highspeed-net/'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hsExt5MEetZ",
        "colab_type": "code",
        "outputId": "7bbe79ba-0331-42b8-aaaa-fb62454bc78d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        }
      },
      "source": [
        "! wget https://raw.githubusercontent.com/andreaaraldo/machine-learning-for-networks/master/9x.ml_highspeed_networks/generator.csv"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-23 17:41:47--  https://raw.githubusercontent.com/andreaaraldo/machine-learning-for-networks/master/9x.ml_highspeed_networks/generator.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 176598 (172K) [text/plain]\n",
            "Saving to: ‘generator.csv’\n",
            "\n",
            "\rgenerator.csv         0%[                    ]       0  --.-KB/s               \rgenerator.csv       100%[===================>] 172.46K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2020-05-23 17:41:47 (3.81 MB/s) - ‘generator.csv’ saved [176598/176598]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "D6H9KDcVMMEy"
      },
      "source": [
        "After importing the main libraries, we can create a shared queue which simulates the physical link between two machines.\n",
        "\n",
        "\n",
        "TXGEN ---> [ shared queue ] ----> RX ----> Processing\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3qcC7yA1MMEz",
        "colab": {}
      },
      "source": [
        "shared = Queue(maxsize=1024)   # Max size of the queue\n",
        "rate = .1 # Rate for the TX generation\n",
        "total_number = 10000  # Max number of packets to transmit\n",
        "duration = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Rj0TxiHVMMFG",
        "colab": {}
      },
      "source": [
        "# TX gen function\n",
        "def txgen(id, l_queue, stop_event):\n",
        "    count= 0\n",
        "    lost = 0\n",
        "\n",
        "    # Read the tx dataset and transform to numpy\n",
        "    full_df = pd.read_csv('generator.csv')\n",
        "    data = full_df.to_numpy()\n",
        "    \n",
        "    # Limit to iterate over the dataset\n",
        "    # Feat to get rid of the labels in the csv\n",
        "    limit = len(data[:,0])\n",
        "    feat = len(data[0,:]) - 2\n",
        "    \n",
        "    while (not stop_event.is_set() ):\n",
        "#    while (total_number > 0 ):\n",
        "\n",
        "        try:\n",
        "            l_queue.put_nowait( data[count%limit,:feat] )\n",
        "            logging.debug(\"Packet added to the queue \" +str(count))\n",
        "        except queue.Full:\n",
        "            logging.debug(\"Packet loss!\")\n",
        "            lost += 1 \n",
        "\n",
        "\n",
        "        count += 1 \n",
        "        logging.debug(\"Total packet sent \" +str(count))\n",
        "        stop_event.wait(timeout=.00001)#        print (\"working on %s\" % arg)\n",
        "\n",
        "    logging.info(\"Sent: %d Lost %d \", count, lost)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Jj9dWjiYMMFN",
        "colab": {}
      },
      "source": [
        "# PROCESSING FUNCTION: You have to modify this function\n",
        "# Hint: Import the traned model, perform the classification task, and then return\n",
        "def processing(element):\n",
        "\n",
        "    ##################################\n",
        "    # Your processing goes here\n",
        "    # after loading a model\n",
        "    # use it to process the element\n",
        "    #\n",
        "    # y_pred = model(element)\n",
        "    #\n",
        "    # You should return the value of the classification task y_pred\n",
        "    #  \n",
        "    # Bonus: You can also compare with the original y from the csv\n",
        "    ##################################\n",
        "\n",
        "    sample = element.reshape(-1,1).T\n",
        "    # predict_fun is to be defined later. Its implementation will depend on the\n",
        "    # model considered\n",
        "    y_pred = predict_fun(sample) \n",
        "\n",
        "\n",
        "    return (y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cCRrCn83MMFV",
        "colab": {}
      },
      "source": [
        "# RX Function\n",
        "def rx(id, l_queue, stop_event):\n",
        "    logging.debug(\"Starting the consumer\")\n",
        "    count = 0\n",
        "\n",
        "    while (not stop_event.is_set()):\n",
        "\n",
        "        try:\n",
        "            logging.debug(\"Reading queue\")\n",
        "            pkt = l_queue.get(timeout=1)\n",
        "            logging.debug(\"Retrieved element\")\n",
        "\n",
        "            # Processing starting... First counter\n",
        "            #t0 = time.clock()\n",
        "            count+=1\n",
        "\n",
        "            #################################\n",
        "            # Processing function. Here you have to put your ML approach\n",
        "            # Pkt is already a numpy element, including all the features but no labels\n",
        "            # The processing task is to classify the pkt\n",
        "            processing(pkt)\n",
        "            #################################\n",
        "\n",
        "            #logging.debug(\"Elapsed time: %.6f\", time.clock() - t0)\n",
        "            logging.debug(\"Count: %d\", count)\n",
        "            \n",
        "        except Exception as e:\n",
        "            print (e)\n",
        "            pass\n",
        "    logging.info(\"Received: %d\", count)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GW-j3gSQMMFb",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "    # Hint: use a global model loaded from the file where you saved your training model\n",
        "    \n",
        "    \n",
        "    # Event variables for the experiment\n",
        "    producer_stop = Event()\n",
        "    consumer_stop = Event()\n",
        "\n",
        "    # Logger: set the logger to level INFO for normal usage, DEBUG for detailed info\n",
        "    logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "    # Here we start the Traffic generator\n",
        "    t = Process(target=txgen, args=(0, shared, producer_stop))\n",
        "    t.start()\n",
        "\n",
        "    # Here we start the receiver\n",
        "    t2 = Process(target=rx, args=(0, shared, consumer_stop))\n",
        "    t2.start()\n",
        "\n",
        "    # Experiment duration\n",
        "    time.sleep(duration)\n",
        "    producer_stop.set()\n",
        "    time.sleep(1)\n",
        "    consumer_stop.set()\n",
        "\n",
        "    t.join()\n",
        "    t2.join()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_oNCHyioNxq",
        "colab_type": "text"
      },
      "source": [
        "# Before you continue\n",
        "\n",
        "It may happen that the `main()` goes on forever. We are sorry for this inconvenient. \n",
        "If this happens, on Google Colab:\n",
        "* Do \"Runtime > Factory Reset runtime\" and run again all the cells up to this current cell (\"Runtime > Run before\"). \n",
        "* Jump directly to the other model you want to try (do not run again a model you have already tried)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxNvj64kekPh",
        "colab_type": "text"
      },
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XK1RXpUlFKjQ",
        "colab_type": "text"
      },
      "source": [
        "Load your previously trained Logistic Regressor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MytIEB0eFMl3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Replace with your filename\n",
        "with open(my_path+\"logistic-reg.pkl\", \"rb\") as dump_file:\n",
        "  model = pickle.load(dump_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m61nX1vZiamH",
        "colab_type": "text"
      },
      "source": [
        "We need to define the predict function. This will be used inside the simulation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPT06Hg_iZRc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_fun(sample):\n",
        "  y_pred = model.predict(sample)\n",
        "  return y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1gSmJy_etQQ",
        "colab_type": "text"
      },
      "source": [
        "Let's run the simulation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iT5erIKVevp4",
        "colab_type": "code",
        "outputId": "3fffb6de-cb88-401c-8665-3f5a6f006401",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "main()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:Sent: 35724 Lost 10221 \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:root:Received: 25503\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5OJswlYeyPZ",
        "colab_type": "text"
      },
      "source": [
        "# Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06tnHjt7dzxH",
        "colab_type": "text"
      },
      "source": [
        "Let's now try with our previously trained neural network.\n",
        "We first load it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tW0TQAYmdyWT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nnfile = nn_file = my_path + 'nn1.h5'\n",
        "model = load_model(nn_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfX3ob4BkIgn",
        "colab_type": "text"
      },
      "source": [
        "We redifine the prediction function. Note that the name of the function to predict in Keras is different than the scikit-learn models, like LogisticRegression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJFEm7TFjNog",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_fun(sample):\n",
        "  y_pred = np.argmax (model(sample, training=False) )\n",
        "  return y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZJcGRtNeTtk",
        "colab_type": "text"
      },
      "source": [
        "We now run again the `main` function, this time model is this new one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmvClVgZeJcH",
        "colab_type": "code",
        "outputId": "f8a72337-8f0d-48d9-c8fc-988f3061a8c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:Sent: 44834 Lost 41440 \n",
            "INFO:root:Received: 3146\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFIQVdIalAwF",
        "colab_type": "text"
      },
      "source": [
        "Observe that we lost a larger fraction of packets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCuUDRSre1Xc",
        "colab_type": "text"
      },
      "source": [
        "# Your own models\n",
        "\n",
        "Try with other models (other NN architectures, other types of classifiers, etc.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZTvm_xwEMMFo",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}