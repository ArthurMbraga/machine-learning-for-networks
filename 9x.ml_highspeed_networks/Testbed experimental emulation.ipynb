{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Queue, Process, Event\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import queue\n",
    "import time\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After importing the main libraries, we can create a shared queue which simulates the physical link between two machines.\n",
    "\n",
    "\n",
    "TXGEN ---> [ shared queue ] ----> RX ----> Processing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared = Queue(maxsize=1024)   # Max size of the queue\n",
    "rate = .1 # Rate for the TX generation\n",
    "total_number = 10000  # Max number of packets to transmit\n",
    "duration = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TX gen function\n",
    "def txgen(id, l_queue, stop_event):\n",
    "    count= 0\n",
    "    lost = 0\n",
    "\n",
    "    # Read the tx dataset and transform to numpy\n",
    "    full_df = pd.read_csv('generator.csv')\n",
    "    data = full_df.to_numpy()\n",
    "    \n",
    "    # Limit to iterate over the dataset\n",
    "    # Feat to get rid of the labels in the csv\n",
    "    limit = len(data[:,0])\n",
    "    feat = len(data[0,:]) - 2\n",
    "    \n",
    "    while (not stop_event.is_set() ):\n",
    "#    while (total_number > 0 ):\n",
    "\n",
    "        try:\n",
    "            l_queue.put_nowait( data[count%limit,:feat] )\n",
    "            logging.debug(\"Packet added to the queue \" +str(count))\n",
    "        except queue.Full:\n",
    "            logging.debug(\"Packet loss!\")\n",
    "            lost += 1 \n",
    "\n",
    "\n",
    "        count += 1 \n",
    "        logging.debug(\"Total packet sent \" +str(count))\n",
    "        stop_event.wait(timeout=.00001)#        print (\"working on %s\" % arg)\n",
    "\n",
    "    logging.info(\"Sent: %d Lost %d \", count, lost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROCESSING FUNCTION: You have to modify this function\n",
    "# Hint: Import the traned model, perform the classification task, and then return\n",
    "def processing(element):\n",
    "\n",
    "    ##################################\n",
    "    # Your processing goes her\n",
    "    # after loading a model\n",
    "    # use it to process the element\n",
    "    #\n",
    "    # y_pred = model(element)\n",
    "    #\n",
    "    # You should return the value of the classification task y_pred\n",
    "    #  \n",
    "    # Bonus: You can also compare with the original y from the csv\n",
    "    ##################################\n",
    "    return (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RX Function\n",
    "def rx(id, l_queue, stop_event):\n",
    "    logging.debug(\"Starting the consumer\")\n",
    "    count = 0\n",
    "\n",
    "    while (not stop_event.is_set()):\n",
    "\n",
    "        try:\n",
    "            logging.debug(\"Reading queue\")\n",
    "            pkt = l_queue.get(timeout=1)\n",
    "            logging.debug(\"Retrieved element\")\n",
    "\n",
    "            # Processing starting... First counter\n",
    "            #t0 = time.clock()\n",
    "            count+=1\n",
    "\n",
    "            #################################\n",
    "            # Processing function. Here you have to put your ML approach\n",
    "            # Pkt is already a numpy element, including all the features but no labels\n",
    "            # The processing task is to classify the pkt\n",
    "            processing(pkt)\n",
    "            #################################\n",
    "\n",
    "            #logging.debug(\"Elapsed time: %.6f\", time.clock() - t0)\n",
    "            logging.debug(\"Count: %d\", count)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print (e)\n",
    "            pass\n",
    "    logging.info(\"Received: %d\", count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Sent: 65636 Lost 0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Received: 65636\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Hint: use a global model loaded from the file where you saved your training model\n",
    "    \n",
    "    \n",
    "    # Event variables for the experiment\n",
    "    producer_stop = Event()\n",
    "    consumer_stop = Event()\n",
    "\n",
    "    # Logger: set the logger to level INFO for normal usage, DEBUG for detailed info\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "    # Here we start the Traffic generator\n",
    "    t = Process(target=txgen, args=(0, shared, producer_stop))\n",
    "    t.start()\n",
    "\n",
    "    # Here we start the receiver\n",
    "    t2 = Process(target=rx, args=(0, shared, consumer_stop))\n",
    "    t2.start()\n",
    "\n",
    "    # Experiment duration\n",
    "    time.sleep(duration)\n",
    "    producer_stop.set()\n",
    "    time.sleep(1)\n",
    "    consumer_stop.set()\n",
    "\n",
    "    t.join()\n",
    "    t2.join()\n",
    "\n",
    "if (__name__ == \"__main__\"):\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The end\n"
     ]
    }
   ],
   "source": [
    "print (\"The end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
